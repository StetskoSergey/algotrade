{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StetskoSergey/algotrade/blob/main/ML1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ihL2u6BB3Y"
      },
      "source": [
        "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cdSLesxBB3Z",
        "outputId": "2726fa2a-1a1e-4d96-d3f8-4986b0f9eb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/algo\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "from io import StringIO\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "import json\n",
        "import numpy as np # библиотека нампи\n",
        "import pandas as pd # библиотека пандас\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt # библиотека матплотлиб для отрисовки\n",
        "from IPython.display import clear_output # очистка вывода в ячейке\n",
        "import pickle\n",
        "import warnings # библиотека сообщений по ошибкам\n",
        "warnings.filterwarnings(\"ignore\") # игнорировать сообщения ошибок\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd ./drive/MyDrive/algo\n",
        "\n",
        "# QuantBook Analysis Tool\n",
        "# For more information see [https://www.quantconnect.com/docs/research/overview]\n",
        "#qb = QuantBook()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "mb5-P5l5MLBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "av5Yr5QZBB3b"
      },
      "outputs": [],
      "source": [
        "def load_obj(name_obj, colab = False):\n",
        "\n",
        "    if colab:\n",
        "      return np.load(f'{name_obj}.npy')\n",
        "\n",
        "    size_limit = 20000\n",
        "    shift = 0\n",
        "    obj_array = []\n",
        "\n",
        "    while qb.ObjectStore.ContainsKey(f'{name_obj}_{shift}'):\n",
        "\n",
        "        # Затем вы можете загрузить его обратно в массив numpy с помощью функции loads()\n",
        "        byte_data = qb.ObjectStore.ReadBytes(f'{name_obj}_{shift}')\n",
        "        x_loaded = pickle.loads(byte_data)\n",
        "        obj_array.append(x_loaded.astype(np.float64))\n",
        "        shift += 1\n",
        "\n",
        "    return np.vstack(obj_array)\n",
        "\n",
        "\n",
        "trainX = load_obj('trainX', True)\n",
        "trainY = load_obj('trainY', True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разделение датасета на обучение и валидизацию"
      ],
      "metadata": {
        "id": "51AW8DypMUub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FmtOioSxBB3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "# Assuming X is your data and y are your labels\n",
        "x_train, x_val, y_train, y_val = train_test_split(trainX, trainY, test_size=0.2, random_state=42, shuffle = True)\n",
        "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, shuffle = True)\n",
        "\n",
        "\n",
        "# Нормировщики\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "# Масштабируем данные (отдельно для X и Y), чтобы их легче было скормить сетке\n",
        "X_SCAILER = MinMaxScaler(feature_range = (0, 1)) #  RobustScaler() # StandardScaler() #\n",
        "X_SCAILER.fit(x_train)                  # обучаем X_SCAILER\n",
        "x_train = X_SCAILER.transform(x_train)  # трансформируем x_train\n",
        "#x_test = X_SCAILER.transform(x_test)      # трансформируем x_val\n",
        "x_val = X_SCAILER.transform(x_val)      # трансформируем x_val\n",
        "\n",
        "# Масштабируем данные (отдельно для X и Y), чтобы их легче было скормить сетке\n",
        "Y_SCAILER = MinMaxScaler(feature_range = (0, 1)) #  RobustScaler() # StandardScaler() #\n",
        "Y_SCAILER.fit(y_train)                    # обучаем Y_SCAILER\n",
        "y_train = Y_SCAILER.transform(y_train)    # трансформируем y_train\n",
        "#y_test = Y_SCAILER.transform(y_test)        # трансформируем y_val\n",
        "y_val = Y_SCAILER.transform(y_val)        # трансформируем y_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разделение данных и подготовка для обучения моделей"
      ],
      "metadata": {
        "id": "j4YCMO7_MdCe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wzxW9U4TBB3c",
        "outputId": "3314e7d2-ce58-4ac6-9111-7e6f63f022ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 1, 3220) (20, 3)\n",
            "(1, 3220)\n"
          ]
        }
      ],
      "source": [
        "# Для генерации выборки временных рядов\n",
        "TSG = tf.keras.preprocessing.sequence.TimeseriesGenerator\n",
        "DEPTH = 1\n",
        "MAKE_LOG = False\n",
        "PREDICT_LAG = 1\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "# Создаем генератор для обучения\n",
        "train_datagen = TSG(x_train, y_train,          # В качестве параметров наши выборки\n",
        "                    length = DEPTH,            # Анализируем по 21 прошедшим точкам\n",
        "                    sampling_rate = 1,         # Для каждой точки\n",
        "                    batch_size = BATCH_SIZE)   # Размер batch, который будем скармливать модели\n",
        "\n",
        "# Создаем аналогичный генератор для валидации при обучении\n",
        "val_datagen = TSG(x_val, y_val,                # В качестве параметров наши выборки\n",
        "                    length = DEPTH,            # Анализируем по 21 прошедшим точкам\n",
        "                    sampling_rate = 1,         # Для каждой точки\n",
        "                    batch_size = BATCH_SIZE)   # Размер batch, который будем скармливать модели\n",
        "\n",
        "print(train_datagen[0][0].shape,\n",
        "      val_datagen[0][1].shape)\n",
        "\n",
        "# запомним входную размерность для модели обучения\n",
        "INSHAPE = train_datagen[0][0].shape[1:]\n",
        "print(INSHAPE)\n",
        "\n",
        "XVAL = x_val.reshape(x_val.shape[0], 1, x_val.shape[1])\n",
        "YVAL = y_val # reshape не делаем так как зачем делать его туда и обратно"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvOKDKhIBB3c"
      },
      "source": [
        "# Классы для генерации случайной нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MiQ3_gdpBB3c"
      },
      "outputs": [],
      "source": [
        "import random as random # Импортируем модель randim\n",
        "import inspect # для получения имен аргументов функции"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB_IRq5GBB3c"
      },
      "source": [
        "# Класс для определения слоев"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3VNQO2aHBB3c"
      },
      "outputs": [],
      "source": [
        "class Set_net():\n",
        "    '''\n",
        "    Класс для формирования списка списков блоков,\n",
        "    имен слоев и значений парамметров слоев\n",
        "    type_net       - тип сети:\n",
        "                     0 - Dense\n",
        "                     1 - Conv\n",
        "                     2 - Recur\n",
        "                     None - любая\n",
        "    activ_lays     - список функций активаций\n",
        "    activ_out      - выходная функция активации\n",
        "    neiro_out      -  количество нейронов/сверток выходного слоя\n",
        "    limit          -  ограничения роста сети\n",
        "                      по умолчание 10**3\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 type_net,      # тип сети\n",
        "                 activ_lays,    # список функций активаций\n",
        "                 activ_out,     # выходная функция активации\n",
        "                 neiro_out,     # количество нейронов/сверток выходного слоя\n",
        "                 limit = 10**3, # ограничения роста сети\n",
        "                 ) -> None:\n",
        "\n",
        "        # списки имен используемых слоев\n",
        "        self.main_lays =  ['Dense', 'Conv1D']\n",
        "        self.recur_lays = ['Lstm', 'BiEmbLstm']\n",
        "        self.add_lays =   ['SCnv1D', 'Conv1DT', 'Conv1D_dilation_block']\n",
        "        self.optim_lays = ['Dropout','BatchN', 'LayNorm']\n",
        "        self.pooling_lays = ['MaxP1D','AvgP1D', 'Ups1D']\n",
        "        self.embed_lays =   ['Embed']\n",
        "        self.activ_lays = activ_lays\n",
        "        self.activ_out = activ_out\n",
        "        self.neiro_out = neiro_out\n",
        "\n",
        "        # все используемые именя слоев\n",
        "        self.use_layers  = self.main_lays + self.recur_lays + self.optim_lays\\\n",
        "                           + self.pooling_lays + self.embed_lays\\\n",
        "                           + self.add_lays + ['activ',]\n",
        "\n",
        "        # создаем self переменные\n",
        "        self.type_net = type_net\n",
        "        self.limit = limit\n",
        "        self.layer = tf.keras.layers\n",
        "\n",
        "        # создаем список функций слоев\n",
        "        self.makers_layer = (self.make_dense,\n",
        "                             self.make_conv1D,\n",
        "                             self.make_lstm,\n",
        "                             self.make_biemblstm,\n",
        "                             self.make_dropout,\n",
        "                             self.make_batchn,\n",
        "                             self.make_laynorm,\n",
        "                             self.make_maxp1D,\n",
        "                             self.make_avg1D,\n",
        "                             self.make_upsam1D,\n",
        "                             self.make_embedding,\n",
        "                             self.make_sepconv1D,\n",
        "                             self.make_conv1DT,\n",
        "                             self.make_convblock_dilation,\n",
        "                             self.make_activ,\n",
        "        )\n",
        "        # создаем словарь соответсвия имен и функций слоев\n",
        "        self.dict_layers = dict(zip(self.use_layers, self.makers_layer))\n",
        "        pass\n",
        "\n",
        "    # Функции создания слоев\n",
        "    def make_dropout(self, x, rate):\n",
        "        lay = self.layer.Dropout(rate)(x)\n",
        "        return lay\n",
        "\n",
        "    def make_batchn(self, x):\n",
        "        lay = self.layer.BatchNormalization()(x)\n",
        "        return lay\n",
        "\n",
        "    def make_laynorm(self, x):\n",
        "        lay = self.layer.LayerNormalization()(x)\n",
        "        return lay\n",
        "\n",
        "    def make_dense(self,x, neiron):\n",
        "        lay = self.layer.Dense(neiron)(x)\n",
        "        return lay\n",
        "\n",
        "    def make_conv1D(self, x, filter, kernel):\n",
        "        # корректируем размерность под conv1D\n",
        "        if len(x.shape) < 3:\n",
        "           x = self.layer.Reshape((-1,1))(x)\n",
        "        lay = self.layer.Conv1D(filters = filter,\n",
        "                                kernel_size = kernel,\n",
        "                                padding = 'same')(x)\n",
        "        return lay\n",
        "\n",
        "    def make_sepconv1D(self, x, filter, kernel):\n",
        "         # корректируем размерность под conv1DT\n",
        "        if len(x.shape) < 3:\n",
        "           x = self.layer.Reshape((-1,1))(x)\n",
        "        lay = self.layer.SeparableConvolution1D(filters = filter,\n",
        "                                                kernel_size = kernel,\n",
        "                                                padding = 'same')(x)\n",
        "        return lay\n",
        "\n",
        "    def make_conv1DT(self, x, filter,  kernel):\n",
        "        # корректируем размерность под conv1DT\n",
        "        if len(x.shape) < 3:\n",
        "           x = self.layer.Reshape((-1,1))(x)\n",
        "        lay = self.layer.Conv1DTranspose(filters = filter,\n",
        "                                         kernel_size = kernel,\n",
        "                                         padding = 'same')(x)\n",
        "        return lay\n",
        "\n",
        "\n",
        "    def make_maxp1D(self, x, pool):\n",
        "        lay = self.layer.MaxPooling1D(pool_size = pool)(x)\n",
        "        return lay\n",
        "\n",
        "    def make_avg1D(self, x, pool):\n",
        "        lay = self.layer.AveragePooling1D(pool_size = pool)(x)\n",
        "        return lay\n",
        "\n",
        "    def make_upsam1D(self, x, upsize):\n",
        "        lay = self.layer.UpSampling1D(size = upsize)(x)\n",
        "        return lay\n",
        "\n",
        "\n",
        "    def make_lstm(self, x, lstmon):\n",
        "        # корректируем размерность под LSTM\n",
        "        if len(x.shape) < 3:\n",
        "           x = self.layer.Reshape((-1,1))(x)\n",
        "        lay = self.layer.LSTM(units = lstmon,\n",
        "                              return_sequences = True,\n",
        "                              )(x)\n",
        "        return lay\n",
        "\n",
        "    def make_embedding(self, x, in_emb, out_emb):\n",
        "        # корректируем размерность под LSTM\n",
        "        if len(x.shape) > 2:\n",
        "          x = self.layer.Flatten()(x)\n",
        "        lay = self.layer.Embedding(input_dim = in_emb,\n",
        "                                             output_dim = out_emb)(x)\n",
        "        return lay\n",
        "\n",
        "    def make_biemblstm(self, x, lstmon):\n",
        "        # корректируем размерность под LSTM\n",
        "        if len(x.shape) > 2:\n",
        "           x = self.layer.Flatten()(x)\n",
        "        # парамметры для Embedding слоя\n",
        "        emb_in = x.shape[1]\n",
        "        emb_out = min(64, emb_in//3)\n",
        "        lay = self.layer.Embedding(input_dim = emb_in,\n",
        "                                              output_dim = emb_out)(x)\n",
        "        lay = self.layer.Bidirectional(self.layer.LSTM(lstmon,\n",
        "                                                      return_sequences=True))(lay)\n",
        "        lay = self.layer.Bidirectional(self.layer.LSTM(lstmon,\n",
        "                                                      return_sequences=False))(lay)\n",
        "        return lay\n",
        "\n",
        "    def make_convblock_dilation(self, x, filter,  kernel):\n",
        "        def convs(x, n, f, rate, ln = False):\n",
        "            x = self.layer.Conv1D(n, f, padding = \"causal\",\n",
        "                            dilation_rate = rate,\n",
        "                            activation=\"sigmoid\")(x)\n",
        "            x = self.layer.LayerNormalization()(x) if ln else x\n",
        "            return x\n",
        "        # корректируем размерность под conv1DT\n",
        "        if len(x.shape) < 3:\n",
        "            x = self.layer.Reshape((-1,1))(x)\n",
        "        a = convs(x = x, n = filter,  f = filter, rate = 2, ln = True)\n",
        "        b = convs(x = x, n = filter,  f = filter, rate = 4, ln = True)\n",
        "        c = convs(x = x, n = filter,  f = filter, rate = 8, ln = True)\n",
        "        d = convs(x = x, n = filter,  f = filter, rate = 16, ln = True)\n",
        "        lay = self.layer.concatenate([x, a, b, c, d], axis = -1)\n",
        "        return lay\n",
        "\n",
        "    def make_activ(self, x, activ):\n",
        "        lay = self.layer.Activation(activ)(x)\n",
        "        return lay\n",
        "\n",
        "\n",
        "    # Метод построение случайного бота блока на основе bot_list блока\n",
        "    def __buildbot__(self, bot_list):\n",
        "        '''\n",
        "        Метод создает случайным образом в заданном диапазоне\n",
        "        значения пришедщим парраметрам слоев в списке bot_list\n",
        "        собирает их в список и выдает этот список\n",
        "        '''\n",
        "        bot = []\n",
        "        for el in bot_list:\n",
        "            if el == 'neiron':\n",
        "                bot.append(2**random.randint(2,7))\n",
        "            if el == 'activ':\n",
        "                bot.append(random.randint(0, len(self.activ_lays)-1))\n",
        "            if el == 'filter':\n",
        "                bot.append(2**random.randint(2,7))\n",
        "            if el == 'kernel':\n",
        "                bot.append(random.randint(2,5))\n",
        "            if el == 'pads':\n",
        "                bot.append(random.choice(('valid','same')))\n",
        "            if el == 'stride':\n",
        "                bot.append(random.randint(1,2))\n",
        "            if el == 'pool':\n",
        "                bot.append(random.randint(2,4))\n",
        "            if el == 'upsize':\n",
        "                bot.append(random.randint(2,4))\n",
        "            if el == 'rate':\n",
        "                bot.append(round(random.random()*0.5,2))\n",
        "            if el == 'lstmon':\n",
        "                bot.append(random.randint(2,30))\n",
        "            if el == 'in_emb':\n",
        "                bot.append(random.randint(10,200))\n",
        "            if el == 'out_emb':\n",
        "                bot.append(max(20, bot[-1]//3))\n",
        "        return bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nql86gbuBB3d"
      },
      "source": [
        "# Класс генерация блоков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H8HMQd1cBB3d"
      },
      "outputs": [],
      "source": [
        "class Make_blocks():\n",
        "    '''\n",
        "    Класс отвечающий за генерацию\n",
        "    блоков сети на основе данных из\n",
        "    ранее инициализированного класса set_net\n",
        "\n",
        "    set_net - класс парамметров сети\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                set_net: object,\n",
        "                ):\n",
        "        # переназначенм переменные из класса set_net\n",
        "        self.set_net = set_net\n",
        "        self.neiro_out = set_net.neiro_out\n",
        "        self.main_lays = set_net.main_lays\n",
        "        self.add_lays = set_net.add_lays\n",
        "        self.recur_lays = set_net.recur_lays\n",
        "        self.activ_out = set_net.activ_out\n",
        "        self.limit = set_net.limit\n",
        "        self.type_net = set_net.type_net\n",
        "\n",
        "        # определяем слои сети на основы заданного типа сети\n",
        "        #############################################\n",
        "        # если тип не задан\n",
        "        if self.type_net == None:\n",
        "            self.net_lays = self.main_lays + self.add_lays + self.recur_lays\n",
        "        # если рекурентный тип сети\n",
        "        elif self.type_net == 2:\n",
        "            self.net_lays = self.recur_lays\n",
        "        # если 0 - Dense или 1 - Conv тип сети\n",
        "        else:\n",
        "            # выбираем из main_lays индексом, который равен типу сети\n",
        "            self.net_lays = [self.main_lays[self.type_net]]\n",
        "        #############################################\n",
        "        # отобранные по типу слою и плюс слои оптимизации\n",
        "        self.__used_lays__ = self.net_lays + self.set_net.optim_lays\n",
        "\n",
        "        pass\n",
        "\n",
        "    # ФУНКЦИИ КОРРЕКЦИИ СПИСКОВ БЛОКОВ\n",
        "    def __correct__(self, block_list: list, name: str,\n",
        "                   level = 0, insert = False):\n",
        "        '''\n",
        "        Метод коррекции пришедщего списка списка\n",
        "        block_list - пришедщий список\n",
        "        level - порог выше котого коррекция\n",
        "        name - имя добавляемого слоя\n",
        "        insert - если True то вставит до последнего,\n",
        "              иначе вставит за последним\n",
        "        '''\n",
        "        # подбрасываем монетку\n",
        "        bias = random.random()\n",
        "        if bias >= level: # если выше порога, то корректируем для вывода\n",
        "            if insert: # вставляем\n",
        "               block_list.insert(-1, name)\n",
        "            else: # добавляем\n",
        "               block_list.append(name)\n",
        "        return block_list\n",
        "\n",
        "    # ФУНКЦИИ ГЕНЕРАЦИИ СПИСКОВ БЛОКОВ\n",
        "    def __generateblock__(self,\n",
        "                        max_lays: int,        # мак.количество слоев в блоке\n",
        "                        prob_mp = 0.47,       # появление пуллинг слоя\n",
        "                        prob_el = 0.65,       # Embedding до LSTM\n",
        "                        prob_ac = 0.33        # появление слоя активации\n",
        "                        ):\n",
        "        '''\n",
        "        Внутренний метод для геннерации списка\n",
        "        из имен слоев\n",
        "        max_lays - мак. возможное количество слоев в блоке\n",
        "        '''\n",
        "        # определяем количество слоев в блоке не более max_lays\n",
        "        layers = random.randint(0, max_lays)\n",
        "        block_list = [] # список для сбора имен слоев\n",
        "        # итерируемся по слоям\n",
        "        for i in range(layers):\n",
        "            if not i: # если 0_й слой\n",
        "              # вставляем случайное имя из слоев сети\n",
        "              block_list = self.__correct__(block_list,\n",
        "                                            random.choice(self.net_lays))\n",
        "            else:\n",
        "              # если пришло имя из слоя оптимизации\n",
        "              if block_list[-1] in self.set_net.optim_lays:\n",
        "                # вставляем случайное имя из слоев сети\n",
        "                block_list = self.__correct__(block_list,\n",
        "                                            random.choice(self.net_lays))\n",
        "              else: # иначе выбираем из слоев сети и оптимизации\n",
        "                block_list = self.__correct__(block_list,\n",
        "                                          random.choice(self.__used_lays__))\n",
        "              # случайное появление пулинга после cвертки\n",
        "              if block_list[-1]==\"Conv1D\" and i < layers:\n",
        "                # случайно по prob_mp добавляем пуллинг слой\n",
        "                block_list = self.__correct__(block_list,\n",
        "                                      random.choice(self.set_net.pooling_lays),\n",
        "                                      level = prob_mp)\n",
        "              # случайное появление Embeding переd LSTM\n",
        "              if block_list[-1]==\"Lstm\" and i < layers:\n",
        "                # случайно по prob_el вставляем Embeding слой переd LSTM\n",
        "                block_list = self.__correct__(block_list,\n",
        "                                            self.set_net.embed_lays[0],\n",
        "                                            level = prob_el,\n",
        "                                            insert = True)\n",
        "              # случайное появление активации\n",
        "              if block_list[-1] != 'activ' and i < layers:\n",
        "                # случайно по prob_ac добавляем 'activ'\n",
        "                block_list = self.__correct__(block_list, 'activ',\n",
        "                                            level = prob_ac)\n",
        "              # если набрали длину\n",
        "              if len(block_list) == layers:\n",
        "                  break\n",
        "\n",
        "        return block_list\n",
        "\n",
        "\n",
        "    def sostav_blockov(self, q_lst: list):\n",
        "        '''\n",
        "        Метод генерирует список из списков блоков\n",
        "        размера полученнного из q_lst\n",
        "        q_lst - список длины количества блоков,\n",
        "                где значения списка определяет\n",
        "                количество слоев в блоке\n",
        "        '''\n",
        "        blockov_list = []\n",
        "        for i in range(len(q_lst)):\n",
        "            block = self.__generateblock__(max_lays = q_lst[i])\n",
        "            blockov_list.append(block)\n",
        "        return  blockov_list\n",
        "\n",
        "\n",
        "    def buildblock_bot(self, block_lst: list):\n",
        "        '''\n",
        "        Метод собирает список списков парамметров\n",
        "        слоев каждого блока будущей сети\n",
        "        block_lst - список списков слоев будущей сети\n",
        "        '''\n",
        "        botov_lst = []\n",
        "        for i in range(len(block_lst)):\n",
        "            # получаем список имен парамметров слоев блока\n",
        "            bot_lst = self.__bot_block__(block_lst[i])\n",
        "            # получаем список самих парамметров слоев блока из имен парамметров\n",
        "            bot = self.set_net.__buildbot__(bot_lst)\n",
        "            botov_lst.append(bot)\n",
        "        return   botov_lst\n",
        "\n",
        "    ######################################################################\n",
        "\n",
        "    # ФУНКЦИИ БОТОВ\n",
        "    # определение состава бота для блока из созданого случайно block_list\n",
        "    def __bot_block__(self, block_list: list):\n",
        "        '''\n",
        "        Метод формирует список списков парамметров слоев в блоках\n",
        "        на основе списка имен слоев блока из block_list\n",
        "        block_list - список имен слоев блока\n",
        "        '''\n",
        "        bot_list = []\n",
        "        for lay in block_list:\n",
        "          if lay == 'activ':\n",
        "              # если имя слоя 'activ', то просто добавляем 'activ'\n",
        "              bot_list.append('activ')\n",
        "          else: # иначе\n",
        "              # созданный в set_net словарь соответсвия\n",
        "              # имен слоев и функций их формирующих\n",
        "              maker_lay = self.set_net.dict_layers[lay]\n",
        "              # методом param_layer определяем парамметры\n",
        "              # у функций формирующих слои\n",
        "              param = self.__param_layer__(maker_lay)\n",
        "              # добавляем эти парамметры в bot_list\n",
        "              if len(param): bot_list += param\n",
        "              else: pass\n",
        "        return bot_list\n",
        "\n",
        "\n",
        "    # Построение случайного бота попупуляции\n",
        "    def buildpopulbot(self, q_tyblocks: int, q_lays: int):\n",
        "        '''\n",
        "        Метод случйно генерирует список, который будет\n",
        "        ботом_попупаляции сетей\n",
        "        q_tyblocks - максимально возможное количество блоков в сети\n",
        "        q_lays - максимально возможное количество слоев в блоках в сети\n",
        "        '''\n",
        "        # генерируем количество блоков\n",
        "        qblocks = random.randint(1, q_tyblocks)\n",
        "        # генерируем количество слоев в блоке\n",
        "        genlays = random.randint(1, q_lays)\n",
        "\n",
        "        # собираем бота популяции\n",
        "        populbot = []\n",
        "        # добавляем ген макс. возможное количество блоков сети популяции\n",
        "        populbot.append(qblocks)\n",
        "        # добавляем ген макс. возможное количество слоев в блоках сети популяции\n",
        "        populbot.append(genlays)\n",
        "        # ген типа данной сети\n",
        "        populbot.append(self.type_net)\n",
        "        # ген делать или нет пред_выходном слой\n",
        "        populbot.append(random.randint(0,1))\n",
        "        # ген ко-ва нейронов/фильтров пред_выходном слое\n",
        "        populbot.append(2**random.randint(2,7))\n",
        "        # ген окон если свертки в пред_выходном слое\n",
        "        populbot.append(random.randint(2,5))\n",
        "        # ген делать/нет слой нормализации перед посл-й активацией\n",
        "        populbot.append(random.randint(0,1))\n",
        "        # ген какую делаем активацию в пред_выходном слое из списка активаций\n",
        "        populbot.append(random.randint(0, len(self.set_net.activ_out)-1))\n",
        "        # ген под сложность сети, будет назначается методом сборки сети\n",
        "        populbot.append(0)\n",
        "        # ген под ярусность сети, будет назначается методом сборки сети\n",
        "        populbot.append(0)\n",
        "        return populbot\n",
        "\n",
        "\n",
        "    # ФУНКЦИИ ФОРМИРОВАНИЯ БЛОКОВ\n",
        "    # без степеней - прямые значения нейронов\n",
        "    def __buildblock__(self, tensor: object,\n",
        "                       block_list: list, bot: list):\n",
        "        '''\n",
        "        Метод строет блок слоев на основе списка\n",
        "        имен слоев блока и им соответствующих бота,\n",
        "        являющегося списком парамметров этих слоев\n",
        "        input:\n",
        "        tensor     - входящий тензор\n",
        "        block_list - список имен слоев блока\n",
        "        bot        - спискок парамметров этих слоев\n",
        "        output:\n",
        "        tensor     - исходящий тензор блока\n",
        "        '''\n",
        "\n",
        "        # будет добавляться больше или меньше 0 значение\n",
        "        # если к-во параметров > или < 1\n",
        "        b=0\n",
        "        # иттерируеимя по слоям блока\n",
        "        for i, lay in enumerate(block_list):\n",
        "          # созданный в set_net словарь соответсвия\n",
        "          # имен слоев и функций их формирующих\n",
        "          maker_lay = self.set_net.dict_layers[lay]\n",
        "          # получаем колчество парамметров функции слоя\n",
        "          k = len(self.__param_layer__(maker_lay))\n",
        "          # формируем список аргументов для функции слоя\n",
        "          if k: # если есть доп.параметры в слое\n",
        "            # получаем доп.параметры в слоя\n",
        "            parametrs = [bot[i+b+j] for j in range(k)]\n",
        "            # собираем аргументы для активации\n",
        "            if lay=='activ':\n",
        "              args = [tensor]+[self.set_net.activ_lays[parametrs[0]]]\n",
        "            # собираем аргументы для других многопарамметных слоев\n",
        "            else: args = [tensor]+parametrs\n",
        "          # собираем аргументы если слой без параммeтров\n",
        "          else: args=[tensor]\n",
        "          # формируем слой на основе нужных и собранных args\n",
        "          tensor = maker_lay(*args)\n",
        "          # обнавляем b\n",
        "          b+=k-1\n",
        "        return tensor # выводим выходной тензор блока\n",
        "\n",
        "\n",
        "    def __buildblockout__(self,\n",
        "                      indata: object,    # входные данные\n",
        "                      bot_pop: list,     # бот популяции (может)\n",
        "                       ):\n",
        "        '''\n",
        "        Метод строет блок слоев на основе списка\n",
        "        имен слоев блока и им соответствующих бота,\n",
        "        являющегося списком парамметров этих слоев\n",
        "        input:\n",
        "        tensor     - входящий тензор\n",
        "        block_list - список имен слоев блока\n",
        "        bot        - спискок парамметров этих слоев\n",
        "        output:\n",
        "        tensor     - исходящий тензор блока\n",
        "        '''\n",
        "        x = indata\n",
        "\n",
        "        if bot_pop[2] == 0:\n",
        "            # Добавление предпоследнего полносвязного слоя\n",
        "            if bot_pop[3]!=0:\n",
        "                x = self.set_net.make_dense(x, bot_pop[4])\n",
        "            # Добавление нормализации перед последним полносвязным слоем\n",
        "            if bot_pop[6]!=0: x = self.set_net.make_batchn(x)\n",
        "\n",
        "        elif bot_pop[2] == 1:\n",
        "            # Добавление предпоследнего conv1D слоя\n",
        "            if bot_pop[3]!=0:\n",
        "                # высчитываеи корректировку размерности тензора под conv1D\n",
        "                newshape = self.__redim__(x.shape[1], 2, sort = 0)\n",
        "                x = tf.keras.layers.Reshape(newshape)(x)\n",
        "                x = self.set_net.make_conv1D(x, bot_pop[4], bot_pop[5])\n",
        "            # Добавление нормализации перед последним полносвязным слоем\n",
        "            if bot_pop[6]!=0: x = self.set_net.make_batchn(x)\n",
        "\n",
        "        elif bot_pop[2] == 2:\n",
        "            # Добавление предпоследнего LSTM слоя\n",
        "            if bot_pop[3]!=0:\n",
        "                # высчитываеи корректировку размерности тензора под lstm\n",
        "                newshape = self.__redim__(x.shape[1], 2, sort = 0)\n",
        "                x = tf.keras.layers.Reshape(newshape)(x)\n",
        "                x = self.set_net.make_lstm(x, bot_pop[4])\n",
        "            # Добавление нормализации перед последним полносвязным слоем\n",
        "            if bot_pop[6]!=0: x = self.set_net.make_batchn(x)\n",
        "\n",
        "        else: pass\n",
        "        return x\n",
        "\n",
        "    ###########################################################\n",
        "    ######         вспомогательные методы класса         ######\n",
        "    ###########################################################\n",
        "    def __param_layer__(self, method: object):\n",
        "        '''\n",
        "        Метод выводит количеству управляющих\n",
        "        парамметров пришедшей функции method\n",
        "        на онове inspect.getfullargspec\n",
        "        method - функция у которой определяютя\n",
        "                 количество управляющих парамметров\n",
        "        '''\n",
        "        return inspect.getfullargspec(method).args[2:]\n",
        "\n",
        "\n",
        "    # простое соединение произвольного к-ва блоков\n",
        "    def __flatconcat__(self, set_blocks: list):\n",
        "        '''\n",
        "        Метод конкантенации списка тензоров блоков\n",
        "        через промежуточный перевод в вектор Flatten\n",
        "        с контролем пространства паремметров и при\n",
        "        превышении к-ва размерностей или размера\n",
        "        паремметров, применение GlobalAveragePooling1D\n",
        "        взамен Flatten\n",
        "        '''\n",
        "        out = []\n",
        "        # иттерируемся по списку тензоров\n",
        "        for i in range(len(set_blocks)):\n",
        "            # не является ли уже вектором\n",
        "            if set_blocks[i].shape != (None, 1):\n",
        "                # Берем shape тензора\n",
        "                control_shape = set_blocks[i].get_shape()\n",
        "                # Если много размерностей или много парамметров у тензора\n",
        "                if np.prod(control_shape[1:]) > self.limit \\\n",
        "                 and len(control_shape) > 3:\n",
        "                    # Добавляем слой GlobalAveragePooling1D\n",
        "                    lay = tf.keras.layers.GlobalAveragePooling1D()(set_blocks[i])\n",
        "                    out.append(lay)\n",
        "                else: # Добавляем слой Flatten\n",
        "                    lay = tf.keras.layers.Flatten()(set_blocks[i])\n",
        "                    out.append(lay)\n",
        "            else: # Иначе выходим\n",
        "                break\n",
        "        # Конкантенируем тензоры по axis = -1 и выводим\n",
        "        out = tf.keras.layers.concatenate(out, axis = -1)\n",
        "        return  out\n",
        "\n",
        "\n",
        "    def __redim__(self, size, dim, sort = None):\n",
        "        '''\n",
        "        Метод метод считает выходной список размерностей\n",
        "        длины dim из прешедшего размера парамметров size,\n",
        "        на основе разложения на простые множители\n",
        "        input:\n",
        "        size - входящий размер размерности слоя\n",
        "        dim  - длина всписка выходной размерности\n",
        "        sort - сортировать ли список простых множителей\n",
        "                как - 0 - возраст-й, 1 - убывающий\n",
        "        output:\n",
        "        outshape - выходной список размерностей\n",
        "                   длины dim\n",
        "        '''\n",
        "        # собираем в res простые множители чиcла n\n",
        "        res, n, d = [], size, 2\n",
        "        while d * d <= n:\n",
        "            if n % d == 0:\n",
        "                res.append(d)\n",
        "                n //= d\n",
        "            else:\n",
        "                d += 1\n",
        "        if n > 1:\n",
        "            res.append(n)\n",
        "        ##########################################\n",
        "\n",
        "        # сортируем или перемешиваем список простых множителей\n",
        "        if sort == 0 or sort == 1:\n",
        "            res = sorted(res, reverse=sort)\n",
        "        else:\n",
        "            res = np.random.permutation(res)\n",
        "        ##########################################\n",
        "\n",
        "        # формируем список размерностей длины dim\n",
        "        s = len(res)//dim  # целое число отношения len(res) и dim\n",
        "        if s >= 1 and dim == 2:\n",
        "            # получим outshape размерности 2 из произведений частей\n",
        "            outshape = [np.prod(res[:s]), np.prod(res[s:])]\n",
        "\n",
        "        elif s >= 1 and dim == 3:\n",
        "            # получим outshape размерности 3 из произведений частей\n",
        "            outshape = [np.prod(res[:s]), np.prod(res[s:2*s]),\n",
        "                         np.prod(res[2*s:])]\n",
        "\n",
        "        elif s < 1 and dim == 3:\n",
        "            s = len(res)//(dim-1)\n",
        "            # получим outshape размерности 2 из произведений частей и\n",
        "            # добавляем ось справа\n",
        "            outshape = [int(np.prod(res[:s])), int(np.prod(res[s:])), 1]\n",
        "\n",
        "        elif (s < 1 and dim == 2) or dim == 1:\n",
        "            # просто добавляем ось справа\n",
        "            outshape = [size, 1]\n",
        "\n",
        "        return outshape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3DN20DEBB3e"
      },
      "source": [
        "# Класс сборки нейронки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-hu2ogrRBB3e"
      },
      "outputs": [],
      "source": [
        "#!pip install stopit -q # установка библиотека контроля времени\n",
        "# Install a pip package in the current Jupyter kernel\n",
        "#import sys\n",
        "#!{sys.executable} -m pip install stopit\n",
        "#from stopit import threading_timeoutable as timeoutable\n",
        "\n",
        "MESSAGE_1 = 'Превышение лимита на сборку модели'\n",
        "TIMELIMIT_1 = 30 # лимит времени в секундах на сборку модели\n",
        "\n",
        "MESSAGE_2 = 'Превышение лимита на тестовое обучение модели'\n",
        "TIMELIMIT_2 = 300 # лимит времени на тестовое обучение модели\n",
        "\n",
        "import asyncio\n",
        "from async_timeout import timeout\n",
        "\n",
        "\"\"\"\n",
        "Module containing \"timeout\" decorator for sync and async callables.\n",
        "\"\"\"\n",
        "\n",
        "import asyncio\n",
        "from concurrent import futures\n",
        "from inspect import iscoroutinefunction\n",
        "from functools import wraps\n",
        "from threading import Thread\n",
        "from typing import Type\n",
        "\n",
        "\n",
        "def timeoutable(\n",
        "    timeout_duration, exception_to_raise: Type[Exception] = TimeoutError, message: str = 'Ошибка времени выполнения'\n",
        "):\n",
        "    \"\"\"\n",
        "    Wraps a function to raise the specified exception if execution time\n",
        "    is greater than the specified timeout.\n",
        "\n",
        "    Works with both synchronous and asynchronous callables, but with synchronous ones will introduce\n",
        "    some overhead due to the backend use of threads and asyncio.\n",
        "\n",
        "        :param float timeout_duration: Timeout duration in seconds. If none callable won't time out.\n",
        "        :param Type[Exception] exception_to_raise: Exception to raise when the callable times out.\n",
        "            Defaults to TimeoutError.\n",
        "        :return: The decorated function.\n",
        "        :rtype: callable\n",
        "    \"\"\"\n",
        "\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            async def async_func():\n",
        "                return func(*args, **kwargs)\n",
        "\n",
        "            thread = _LoopWrapper()\n",
        "            thread.start()\n",
        "            future = asyncio.run_coroutine_threadsafe(async_func(), thread.loop)\n",
        "            try:\n",
        "                result = future.result(timeout_duration)\n",
        "            except futures.TimeoutError:\n",
        "                thread.stop_loop()\n",
        "                result = f'{message}'\n",
        "                # raise exception_to_raise()\n",
        "            thread.stop_loop()\n",
        "            return result\n",
        "\n",
        "        @wraps(func)\n",
        "        async def async_wrapper(*args, **kwargs):\n",
        "            try:\n",
        "                value = await asyncio.wait_for(\n",
        "                    func(*args, **kwargs), timeout=timeout_duration\n",
        "                )\n",
        "                return value\n",
        "            except asyncio.TimeoutError:\n",
        "                return f'{message}'\n",
        "                # raise exception_to_raise()\n",
        "\n",
        "        if iscoroutinefunction(func):\n",
        "            return async_wrapper\n",
        "        return wrapper\n",
        "\n",
        "    return decorator\n",
        "\n",
        "\n",
        "class _LoopWrapper(Thread):\n",
        "    def __init__(self):\n",
        "        super().__init__(daemon=True)\n",
        "        self.loop = asyncio.new_event_loop()\n",
        "\n",
        "    def run(self) -> None:\n",
        "        self.loop.run_forever()\n",
        "        self.loop.call_soon_threadsafe(self.loop.close)\n",
        "\n",
        "    def stop_loop(self):\n",
        "        for task in asyncio.all_tasks(self.loop):\n",
        "            task.cancel()\n",
        "        self.loop.call_soon_threadsafe(self.loop.stop)\n",
        "\n",
        "\n",
        "#def my_decorator(input_arg):\n",
        "#    def the_real_decorator(function):\n",
        "#        def wrapper(*args, **kwargs):\n",
        "#            result = function(*args, **kwargs)\n",
        "#            return f'{input_arg}\\\\n{result}\\\\n{input_arg}'\n",
        "#        return wrapper\n",
        "#    return the_real_decorator\n",
        "\n",
        "#def timeoutable(input_arg):\n",
        "#    def the_real_decorator(function):\n",
        "#        async def wrapper(*args, **kwargs):\n",
        "#            wait_sec = 20\n",
        "#            async with timeout(wait_sec) as cm:\n",
        "#                await result = function(*args, **kwargs)\n",
        "#            if cm.expired:\n",
        "#                print(input_arg)\n",
        "#        return wrapper\n",
        "#   return the_real_decorator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FUlLIWjeBB3e"
      },
      "outputs": [],
      "source": [
        "class WildregressModel():\n",
        "      '''\n",
        "      Класс который формирует и выдает сеть\n",
        "\n",
        "      input_shape - размерность входящих в сеть данных\n",
        "      control_level_shape - размер допустимого размера парамметров\n",
        "                            слоев когда требуется применение\n",
        "                            GlobalAveragePooling1D для понижения\n",
        "                            размерности, по умолчанию 10**3\n",
        "      q_level - количество блоков с которого можно строить\n",
        "                многоярусную сет, по умолчанию 3\n",
        "      '''\n",
        "\n",
        "      def __init__(self,\n",
        "                  input_shape: list,\n",
        "                  control_level_shape = 10**3,\n",
        "                  q_level = 3\n",
        "                  ):\n",
        "\n",
        "          self.input_shape = input_shape\n",
        "          self.control = control_level_shape\n",
        "          self.q_level = q_level\n",
        "          pass\n",
        "\n",
        "      # Декоратор для контроля времени\n",
        "      @timeoutable(TIMELIMIT_1, message = MESSAGE_1)\n",
        "      def __call__(self,\n",
        "                  bot_pop: list,\n",
        "                  bot: list,\n",
        "                  setblockov: list,\n",
        "                  blocks: object\n",
        "                  ):\n",
        "          '''\n",
        "          Класс который формирует и выдает сеть на основе\n",
        "          bot_pop - бот_популяции сетей\n",
        "          bot - спискок парамметров слоев блоков\n",
        "          setblockov - списка списков слоев имен блока\n",
        "          blocks - класс построения блоков\n",
        "          '''\n",
        "          # Входной слой\n",
        "          inputs =  tf.keras.layers.Input(self.input_shape)\n",
        "          # размерность даннх сети без 0го, которы None\n",
        "          dim_net = len(self.input_shape) - 1\n",
        "\n",
        "          ##### отбор блоков с основными слоями для входа нейронки ############\n",
        "          idx=[] # хранения индексов блоков с основными слями сети\n",
        "          # отбираем индексы блоков с основными слями сети\n",
        "          for block in setblockov:\n",
        "              if [x for x in blocks.net_lays if x in block]:\n",
        "                idx.append(setblockov.index(block))\n",
        "          # берем первый по счету, и если был посев, для входа уходит сразу\n",
        "          in_nb = idx[0]\n",
        "          # получаем тензор от первого блока\n",
        "          in_block = blocks.__buildblock__(inputs, setblockov[in_nb],\n",
        "                                           bot[in_nb])\n",
        "\n",
        "          #####################################################################\n",
        "          ############# отбор для скрытых блоков ##############################\n",
        "          # ищем и оставляем только один пустой блок\n",
        "          new_setblockov = []\n",
        "          new_bot = []\n",
        "          emp = 0 # счетчик пустых блоков\n",
        "\n",
        "          # Если был посев, то первый блок для входа уходит сразу -\n",
        "          for i in range(1,len(setblockov)): # не попадет во внутр.блоки\n",
        "              #print('metka 4')\n",
        "              if emp == 0 and setblockov[i] == []:\n",
        "                  new_setblockov.append(setblockov[i])\n",
        "                  new_bot.append(bot[i])\n",
        "                  emp+= 1\n",
        "              elif emp != 0 and setblockov[i] == []:\n",
        "                  pass\n",
        "          # оставляем только один пустой блок\n",
        "          # на его основе создается проброс от входной части до concat\n",
        "              else:\n",
        "                  new_setblockov.append(setblockov[i])\n",
        "                  new_bot.append(bot[i])\n",
        "\n",
        "          #####################################################################\n",
        "          #  print('Сборка многоярусной модели')\n",
        "          #####################################################################\n",
        "          if len(new_setblockov) > self.q_level:\n",
        "              ############### БЛОК соединения скрытых блоков  #################\n",
        "              ########## создание гена для ярусности и  сложности сети ########\n",
        "              if not bot_pop[9]:\n",
        "                  # определяем ярусность сети\n",
        "                  bot_pop[8] = random.choice(np.arange(2,\n",
        "                                                       len(new_setblockov)-1))\n",
        "                   # отбор блоков в ярусы\n",
        "                  bot_pop[9] = [0] + [len(new_setblockov)] \\\n",
        "                                   + sorted(np.random.choice(np.arange(1,\n",
        "                                            len(new_setblockov)-1),\n",
        "                                            bot_pop[8], replace=False))\n",
        "                  tiers = bot_pop[9]  # состав ярусов\n",
        "              else:\n",
        "                  tiers = bot_pop[9]  # состав ярусов\n",
        "            ###################################################################\n",
        "              brickblock = [] # ссписок для сборв внутренних блоков\n",
        "              # итеррируемся по ярусам\n",
        "              for j in range(len(tiers)-1):\n",
        "                  indata = in_block if not j else concdata\n",
        "                  hidblock = []\n",
        "                  # отбираем в conc только возможные блоки\n",
        "                  for i in range(tiers[j], tiers[j+1]):\n",
        "                      ##########################################################\n",
        "                      # создаем внутренний блок\n",
        "                      hid = blocks.__buildblock__(indata,\n",
        "                                              new_setblockov[i],\n",
        "                                              new_bot[i])\n",
        "                      # собираем список внутренних блоков для конкатенации\n",
        "                      hidblock.append(hid)\n",
        "                  # еслм набрали в список внутренних блоков\n",
        "                  if len(hidblock):\n",
        "                    # конкатенируем через выпрямления в вектора\n",
        "                    concdata = blocks.__flatconcat__(hidblock)\n",
        "                    # ищем замену размерности\n",
        "                    newshape = blocks.__redim__(concdata.shape[-1],\n",
        "                                                dim_net+1,\n",
        "                                                sort = 0)\n",
        "                    # трансформируем размерность тензора\n",
        "                    concdata = tf.keras.layers.Reshape(newshape)(concdata)\n",
        "                    brickblock.append(concdata)\n",
        "              # соединяем блоки\n",
        "              to_out = blocks.__flatconcat__(brickblock)\n",
        "              # передаем в метод создания продпоследнего блока\n",
        "              out_block = blocks.__buildblockout__(to_out, bot_pop)\n",
        "              # пробрасываем данные с входного блока и соединяем с другими блоками\n",
        "              out_block = blocks.__flatconcat__([in_block, out_block])\n",
        "\n",
        "          # Если есть блоки для одноэтажной модели\n",
        "          elif len(new_setblockov):\n",
        "          #####################################################################\n",
        "          #    print('Сборка одноэтажной модели')\n",
        "          #####################################################################\n",
        "              hidblock = []\n",
        "              for i in range(len(new_setblockov)):\n",
        "                  hid =  blocks.__buildblock__(in_block, new_setblockov[i],\n",
        "                                           new_bot[i])\n",
        "                  hidblock.append(hid)\n",
        "              ################################################################\n",
        "              # соединяем блоки\n",
        "              to_out = blocks.__flatconcat__(hidblock)\n",
        "              # передаем в метод создания продпоследнего блока\n",
        "              out_block = blocks.__buildblockout__(to_out, bot_pop)\n",
        "              # пробрасываем данные с входного блока и соединяем с другими блоками\n",
        "              out_block = blocks.__flatconcat__([in_block, out_block])\n",
        "\n",
        "          # Если нет блоков, то берем тензор с входного блока\n",
        "          else:\n",
        "              # переводим в вектор входной тензор\n",
        "              in_block_out = blocks.__flatconcat__([in_block])\n",
        "              # передаем в метод создания продпоследнего блока\n",
        "              out_block = blocks.__buildblockout__(in_block_out, bot_pop)\n",
        "              # пробрасываем данные с входного блока и соединяем с другими блоками\n",
        "              out_block = blocks.__flatconcat__([in_block, out_block])\n",
        "\n",
        "          # Финальный слой под вашу задачу\n",
        "          out = tf.keras.layers.Dense(units = blocks.neiro_out,\n",
        "                                      activation = blocks.activ_out[bot_pop[7]]\n",
        "                                      )(out_block)\n",
        "          # формируем граф модели\n",
        "          model = tf.keras.Model(inputs, out)\n",
        "          return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlfWhVKrBB3f"
      },
      "source": [
        "# Функции оценки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYp8ldLWBB3f"
      },
      "source": [
        "# функция для оценки и отрисовки автокорреляции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ykwqXs0XBB3f"
      },
      "outputs": [],
      "source": [
        "# Функция рассчитываем результаты прогнозирования сети\n",
        "def get_scalepred(model: object, x: list, y: list, у_scaler: object):\n",
        "  '''\n",
        "  Функция рассчитываем результаты прогнозирования сети\n",
        "  В аргументы принимает сеть (model) и проверочную выборку\n",
        "  Выдаёт результаты предсказания y_pred\n",
        "  И правильные ответы в исходной размерности y_true (какими они были до нормирования)\n",
        "  model - нейронная сеть\n",
        "  x - x данные для предикта\n",
        "  y - y проверочные данные\n",
        "  у_scaler - ранее обученный скэйлер для y\n",
        "\n",
        "  '''\n",
        "  # Предсказываем ответ сети по проверочной выборке\n",
        "  # И возвращаем исходны масштаб данных, до нормализации\n",
        "  y_pred = model.predict(x)\n",
        "  y_pred = у_scaler.inverse_transform(y_pred)\n",
        "  y_true = у_scaler.inverse_transform(y)\n",
        "  if MAKE_LOG:\n",
        "    y_pred = np.exp(y_pred)\n",
        "    y_true = np.exp(y_true)\n",
        "  return (y_pred, y_true)\n",
        "\n",
        "\n",
        "# Функция визуализирует графики, что предсказала сеть и какие были правильные ответы\n",
        "# было бы здорово увидеть как отличаются предсказанные данные и реальные\n",
        "# для этого предположим, что предсказание дает +1 и ставит take_profit, тогда мы добавляем к текущему значению цены +1 в размере take_profit\n",
        "#  реальные данные точно также отрисуем ...\n",
        "# на следующем шаге, если нужно скорректировать обратное движение, на факт, чтобы к следующей итерации правильно добавить дальнейший рост\n",
        "# это место нужно додумать и расписать ... например если направление предсказало неправильно, нужно чтобы сработал stop_loss\n",
        "def show_predict(start: int, finish: int, pred_lags: int,\n",
        "                 y_pred: list, y_true: list, name: str, figsize=(25,10)):\n",
        "  '''\n",
        "  Функция визуализирует графики, что предсказала сеть и какие были правильные ответы\n",
        "  start - точка с которой начинаем отрисовку графика\n",
        "  finish - длина графика, которую отрисовываем\n",
        "  pred_lags - какие шаги предсказания отрисовываем\n",
        "  y_pred - предсказания модели\n",
        "  y_true - верные ответы\n",
        "  name - имя предсказания\n",
        "  '''\n",
        "  plt.figure(figsize=(figsize))\n",
        "  for lag in pred_lags:\n",
        "      plt.plot(y_pred[start:start+finish, lag],\n",
        "              label=f'Прогноз на {lag+1}й шаг')\n",
        "      plt.plot(y_true[start:start+finish, lag],\n",
        "              label=f'Базовый ряд на {lag+1}м шаге')\n",
        "  plt.xlabel('Отсчеты')\n",
        "  plt.ylabel(f'Значение {name}')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Функция расёта корреляции дух одномерных векторов\n",
        "def correlate(a, b):\n",
        "  '''\n",
        "  # Функция расчёта корреляции дух одномерных векторов\n",
        "  a, b - вектора\n",
        "  '''\n",
        "  # Рассчитываем основные показатели\n",
        "  ma = a.mean() # Среднее значение первого вектора\n",
        "  mb = b.mean() # Среднее значение второго вектора\n",
        "  mab = (a*b).mean() # Среднее значение произведения векторов\n",
        "  sa = a.std() # Среднеквадратичное отклонение первого вектора\n",
        "  sb = b.std() # Среднеквадратичное отклонение второго вектора\n",
        "\n",
        "  #Рассчитываем корреляцию\n",
        "  val = 0\n",
        "  if ((sa>0) & (sb>0)):\n",
        "    val = (mab-ma*mb)/(sa*sb)\n",
        "  return val\n",
        "\n",
        "\n",
        "# Функция рисуем корреляцию прогнозированного сигнала с правильным\n",
        "# Нужно смотреть корреляцию сводного сигнала, направление движения и Take_profit\n",
        "def auto_corr(pred_lags: list, corr_steps: list, y_pred: list, y_true: list,\n",
        "             show_graf = True, return_data = False, figsize=(18,7)):\n",
        "  '''\n",
        "  Функция рисуем корреляцию прогнозированного сигнала с правильным\n",
        "  Смещая на различное количество шагов назад\n",
        "  Для проверки появления эффекта автокорреляции\n",
        "  pred_lags -  какие шаги предсказания для проверки корреляцию\n",
        "  corr_steps - на какое количество шагов смещать сигнал назад для рассчёта корреляции\n",
        "  show_graf - показываем график или нет\n",
        "  return_data - возвращаем массивы автокорреляции или нет\n",
        "  '''\n",
        "  # Запоминаем размер проверочной выборки\n",
        "  y_len = y_true.shape[0]\n",
        "  # Если нужно показать график\n",
        "  if show_graf:\n",
        "    plt.figure(figsize=(figsize))\n",
        "  # Проходим по всем каналам\n",
        "  for lag in pred_lags:\n",
        "    # Создаём пустой лист, в нём будут корреляции при смещении на i шагов обратно\n",
        "    corr = []\n",
        "    # Создаём пустой лист, в нём будут самокорреляции графика с собой\n",
        "    # при смещении на i шагов обратно\n",
        "    own_corr = []\n",
        "    # Смещаем сигнал по предсказаниям для проверки автокорреляции\n",
        "    for i in range(corr_steps):\n",
        "      #print('i', i)\n",
        "      # Получаем сигнал, смещённый на i шагов назад\n",
        "      # y_pred[i:, lag]\n",
        "      # Сравниваем его с верными ответами, без смещения назад\n",
        "      # y_true[:y_len-i, lag]\n",
        "      # Рассчитываем их корреляцию и добавляем в лист\n",
        "      corr.append(correlate(y_true[:y_len-i, lag], y_pred[i:, lag]))\n",
        "      # Рассчитываем корреляцию графика самого с сообой и добавляем в лист\n",
        "      own_corr.append(correlate(y_true[:y_len-i, lag], y_true[i:, lag]))\n",
        "\n",
        "    # Отображаем график коррелций для данного шага\n",
        "    if show_graf: # Если нужно показать график\n",
        "      plt.plot(corr, label= f'Предсказание на {str(lag+1)}й шаг')\n",
        "      plt.plot(own_corr, label=f'Эталон на {str(lag+1)}м шаге')\n",
        "  # Если нужно показать график\n",
        "  if show_graf:\n",
        "    plt.xlabel('Отсчеты')\n",
        "    plt.ylabel('Значение корреляции')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  # Если нужно вернуть массивы автокорреляции\n",
        "  if return_data:\n",
        "    return corr, own_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l14ciLf9BB3f"
      },
      "source": [
        "# функция для комплексной оценки сети\n",
        "чистка памяти - https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J0T5s5qmBB3f"
      },
      "outputs": [],
      "source": [
        "import time # библиотека времени\n",
        "import gc\n",
        "\n",
        "# Колбек для подсчета в функции ниже средней скорости на эпохе\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    # создаем пустой список вначале обучения\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "    # запоминаем время вначале эпохи\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "    # запоминаем время обучения на эпохе\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        # добавляем в список в конце эпохи\n",
        "        self.times.append(time.time() - self.epoch_time_start)\n",
        "\n",
        "# Custom Callback To Include in Callbacks List At Training Time\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "# Функция на оценки с добавленным колбеком времени\n",
        "@timeoutable(TIMELIMIT_2, message = MESSAGE_2) # Декоратор для контроля времени\n",
        "def evaluate_model(model, y_scaler, train_gen,\n",
        "                   val_gen, ep, verb, optimizer,\n",
        "                   loss, channels, predict_lag):\n",
        "      '''\n",
        "      Функция оценки модели на точность и автокорреляцию, с обучение\n",
        "      и проверкой эффекта автокорреляции\n",
        "      model       - тестируемая модель\n",
        "      y_scaler    - ранее обученный скэйлер для ответов\n",
        "      train_gen   - генератор данных для обучения модели\n",
        "      val_gen     - генератор данных для проверки модели\n",
        "      ep          - количество эпох оценосного обучения\n",
        "      verb        - показывать ли процесс обучения\n",
        "      optimizer   - используемый оптимайзер для обучения\n",
        "      loss        - используемая функция потерь для обучения\n",
        "      channels    - каналы в ответе модели для проверки автокорреляции\n",
        "      predict_lag - на сколько шагом предсказание\n",
        "      '''\n",
        "      # сбрасываем оценку на случай пересечения названия с global переменной\n",
        "      val = 0\n",
        "      # Компилируем модель\n",
        "      model.compile(optimizer, loss)\n",
        "      # инициализируем колбек в дальнейшем для поиска более быстрых и оптимизации поиска\n",
        "      time_callback = TimeHistory()\n",
        "      # очистка ОЗУ\n",
        "      clear_ozu = GarbageCollectorCallback()\n",
        "      # обучаем модель\n",
        "      history = model.fit(train_gen,\n",
        "                          epochs=ep,\n",
        "                          verbose=verb,\n",
        "                          validation_data=val_gen,\n",
        "                          callbacks=[time_callback, clear_ozu])\n",
        "      # получаем данные по времени каждой эпохи\n",
        "      times_back = time_callback.times\n",
        "      # берем среднее время эпохи\n",
        "      time_ep = np.mean(times_back)\n",
        "\n",
        "      # Прогнозируем данные текущей сетью\n",
        "      (pred_val, y_val_true) = get_scalepred(model, XVAL, YVAL, y_scaler)\n",
        "      # Возвращаем автокорреляцию\n",
        "      corr, own_corr = auto_corr(pred_lags = channels,\n",
        "                                 corr_steps = predict_lag,\n",
        "                                 y_pred = pred_val,\n",
        "                                 y_true = y_val_true,\n",
        "                                 show_graf = False,\n",
        "                                 return_data = True)\n",
        "      # Считаем MAE автокорреляции и умножаем (прибавляем) ошибку обучения\n",
        "      val = 100*tf.keras.losses.MAE(corr, own_corr).numpy()*history.history[\"val_loss\"][-1]\n",
        "\n",
        "      # чистим память\n",
        "      tf.keras.backend.clear_session()\n",
        "      del model\n",
        "      gc.collect()\n",
        "      # Возвращаем точность и среднее время эпохи\n",
        "      return val, time_ep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcy72y4QBB3f"
      },
      "source": [
        "# Генетический отбор нейронок"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dba01ao8BB3f"
      },
      "source": [
        "# Функции для посева сетей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vqLPYk5TBB3f"
      },
      "outputs": [],
      "source": [
        "# функция для ввода ботов и состава блоков моделей нейронок\n",
        "def posev_net():\n",
        "    '''\n",
        "    Функция для передачи посева вначале генетического отбора вручную.\n",
        "    Вначале нужно будет ввести число сеемых сетей,\n",
        "    если 0, то код пойдет далее с 0,\n",
        "    если 1, 2 или n натуральное число, то это кол-во сеемых сетей.\n",
        "    нужно будет передать для каждой сети свой набор:\n",
        "    [bot_pop] - бот популяции вида [7, 1, 0, 1, 16, 7, 0, 0, 0, 0]\n",
        "    [blockov_list] - список слоев блоков вида [[], [], ['Conv1DT'], ['Dense'], [], [], []]\n",
        "    [bot] - список параметров слоев блоков вида [[], [], [32, 5], [256], [], [], []]\n",
        "\n",
        "    '''\n",
        "    nets = int(input('Укажите количество сетей для посева: '))\n",
        "    posev = []\n",
        "    if nets == 0:\n",
        "      bot_pop = [4, 1, None, 1, 128, 6, 0, 0, 0, 0]\n",
        "      setblockov = [[], ['Lstm'], ['Conv1D_dilation_block'], []]\n",
        "      bot = [[], [4], [8, 2], []]\n",
        "      net = []\n",
        "      net.append(bot_pop)\n",
        "      net.append(setblockov)\n",
        "      net.append(bot)\n",
        "      posev.append(net)\n",
        "      return posev\n",
        "    for i in range(nets):\n",
        "        net=[]\n",
        "        botpop_net  = eval(input('Введите лист бота популяции сети:'))\n",
        "        net.append(botpop_net)\n",
        "        blockovlst_net = eval(input('Введите лист блоков сети:'))\n",
        "        net.append(blockovlst_net)\n",
        "        bot_net = eval(input('Введите бот_лист параметров слоев сети:'))\n",
        "        net.append(bot_net)\n",
        "        posev.append(net)\n",
        "    return posev\n",
        "\n",
        "# функция определения индексов лучших\n",
        "def get_idxbest(sval: list, best: int):\n",
        "    '''\n",
        "    Функция для получения индексов и точностей\n",
        "    из матрицы\n",
        "    Args:\n",
        "      sval -  сортированная матрицы оценок\n",
        "      int - нужно количество лучших\n",
        "    Return:\n",
        "      idxs - индексы лучших\n",
        "      sval_best - оценки лучших\n",
        "    '''\n",
        "    flt =  np.array(sval).ravel()  # вытягиваем массив\n",
        "    flt = np.sort(flt)# сортируем слева направо\n",
        "    # ищем индексы best лучших\n",
        "    idxs = np.array([np.array(np.where(sval == flt[i])).ravel()\n",
        "                     for i in range(best)])\n",
        "    sval_best = flt[:best]\n",
        "    return idxs, sval_best\n",
        "\n",
        "# функция получения списка лучших сетей\n",
        "def get_bestnets(idxs, botpop_lst, mega_info, mega_popul):\n",
        "    '''\n",
        "    Функция для получения списка лучших сетей для подсева\n",
        "    в процессе генетического отбора.\n",
        "    из матрицы\n",
        "    Args:\n",
        "      botpop_lst - список списков ботов самих популяций\n",
        "      mega_info  - список списков имен слоев всех сетей всех популяций\n",
        "      mega_popul - список списков парамметров слоев всех сетей всех популяций\n",
        "    Return:\n",
        "      thebestnets - лучших сетей взятых по индексам idxs\n",
        "    '''\n",
        "    thebestnets = []\n",
        "    for id in idxs:\n",
        "        net=[]\n",
        "        i = id[0]\n",
        "        j = id[1]\n",
        "        botpop_net  = botpop_lst[i]\n",
        "        net.append(botpop_net)\n",
        "        blockovlst_net = mega_info[i]\n",
        "        net.append(blockovlst_net)\n",
        "        bot_net = mega_popul[i][j]\n",
        "        net.append(bot_net)\n",
        "        thebestnets.append(net)\n",
        "    return thebestnets\n",
        "\n",
        "def getnetfrombest(thebestnets: list, activ_lays: list,\n",
        "                   activ_out:list, neiro_out: int,\n",
        "                   limit = 10,\n",
        "                   n = 1):\n",
        "    '''\n",
        "    Функция поулченмя смискм из моделей, которые генерируются\n",
        "    из списка списков парамметров сетей из генгетического отбора\n",
        "    Args:\n",
        "      thebestnets - список списков списков по структуре отобранных сетей тип:\n",
        "                [[[bot_pop_1],[blockov_list_1],[bot_1]],\n",
        "                [[bot_pop_1],[blockov_list_1],[bot_1]]]\n",
        "      activ_lays - список возможных активац. функций внутри сети\n",
        "      activ_out - список возможных активац. функций выхода сети\n",
        "      neiro_out - кол-во выходных нейронов\n",
        "      limit - лимит на сборку модели\n",
        "      n - количество выводимых сетей\n",
        "    Return:\n",
        "       modlbest_lst - список сгенерированных сетей длины n\n",
        "    '''\n",
        "    modlbest_lst = []\n",
        "    for i in range(n):\n",
        "      # определяем тип создания модели\n",
        "      choosed_net = Set_net(thebestnets[i][0][2], activ_lays,\n",
        "                            activ_out, neiro_out)\n",
        "      # инициализируем класс структуры блоков на основе парраметров сети\n",
        "      maker_blocks = Make_blocks(choosed_net)\n",
        "      # инициализируем класс формирования сети\n",
        "      make_model = WildregressModel(INSHAPE)\n",
        "\n",
        "      model_best = make_model(thebestnets[i][0], # бот_популяции сетей\n",
        "                              thebestnets[i][2],  # бот парамметров слоев сети\n",
        "                              thebestnets[i][1] , # список имен слоев сети\n",
        "                              maker_blocks # класс построения блоков\n",
        "                              )\n",
        "      modlbest_lst.append(model_best)\n",
        "    return modlbest_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iejfp6jBB3f"
      },
      "source": [
        "# Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lFm5Ge5jBB3f"
      },
      "outputs": [],
      "source": [
        "def show_pocess_1(avlmdl_lst: list, gdmdl_lst: list,\n",
        "                  sval_lst: list, seff_lst: list):\n",
        "    '''\n",
        "    Функция отображает процесс создания моделей и\n",
        "    точность с эффективностью лучшей\n",
        "    Args:\n",
        "      avlmdl_lst - Доля созданных моделей\n",
        "      gdmdl_lst - Доля пригодных моделей\n",
        "      sval_lst - Ошибка лучшей в популяции\n",
        "      seff_lst - Эффективность лучшей в популяции\n",
        "    '''\n",
        "    plt.figure(1, figsize=(18,6))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Динамика создания моделей')\n",
        "    plt.plot(avlmdl_lst, label = 'Доля созданных моделей')\n",
        "    plt.plot(gdmdl_lst, label = 'Доля пригодных моделей')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('Динамика поиска моделей')\n",
        "    if len(sval_lst) > 15:\n",
        "        plt.plot(sval_lst[-15:], label = 'Ошибка лучшей в популяции')\n",
        "        plt.plot(seff_lst[-15:], label = 'Эффективность лучшей в популяции')\n",
        "    else:\n",
        "        plt.plot(sval_lst, label = 'Ошибка лучшей в популяции')\n",
        "        plt.plot(seff_lst, label = 'Эффективность лучшей в популяции')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def show_process_2(svalp_lst:list, seffp_lst:list, ephtime_lst:list):\n",
        "    '''\n",
        "    Функция динамику поиска лучшей модели от эпохи\n",
        "    Args:\n",
        "      svalp_lst - Ошибка лучшей модели\n",
        "      seffp_lst - Эффективность лучшей модели\n",
        "    '''\n",
        "    plt.figure(1, figsize=(18,6))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('Динамика поиска лучшей модели  от эпохи')\n",
        "    if len(svalp_lst) > 50:\n",
        "        plt.plot(svalp_lst[-50:], label = 'Ошибка лучшей модели')\n",
        "        plt.plot(seffp_lst[-50:], label = 'Эффективность лучшей модели')\n",
        "    else:\n",
        "        plt.plot(svalp_lst, label = 'Ошибка лучшей модели')\n",
        "        plt.plot(seffp_lst, label = 'Эффективность лучшей модели')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('Время поиска от эпохи')\n",
        "    plt.plot(ephtime_lst)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6I8wGtxCBB3f"
      },
      "outputs": [],
      "source": [
        "def get_var_name(variable):\n",
        "    '''\n",
        "    Функция получения имени переменной в виде строки\n",
        "    на основе глобальной видимости\n",
        "    пример https://www.programiz.com/python-programming/methods/built-in/globals\n",
        "    variable - переменная\n",
        "    '''\n",
        "    globals_dict = globals()\n",
        "    var_name = [var_name for var_name in globals_dict\n",
        "                if globals_dict[var_name] is variable\n",
        "                  ][0]\n",
        "    return var_name\n",
        "\n",
        "def saver(lists_datas: list, directory: str):\n",
        "    '''\n",
        "    Функция сохраняет список с именем переменной\n",
        "    в списке на основы функции, выдающей имя переменной\n",
        "    get_var_name\n",
        "      Args:\n",
        "      lists_datas - список из сохраняемых списков\n",
        "      directory - директория, куда пишем\n",
        "    '''\n",
        "    for data in lists_datas:\n",
        "        name_obj = get_var_name(data)\n",
        "        x_bytes = pickle.dumps(data)\n",
        "        qb.ObjectStore.SaveBytes(f'genetic {name_obj}', x_bytes)\n",
        "        #np.save(directory + name + '.npy', data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2Nxe2YwBB3g"
      },
      "outputs": [],
      "source": [
        "# пояснение как работает получение имени переменной строкой\n",
        "a = [1,2]\n",
        "b = [2,3]\n",
        "c = [a, b]\n",
        "for name in c:\n",
        "  print(get_var_name(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrOqb_VoBB3g"
      },
      "source": [
        "# **Основная обработка посева и подбора моделей**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_tit3LyBB3g"
      },
      "outputs": [],
      "source": [
        "# часть лучших сетей одного отбора\n",
        "#bn_1 = np.load('.. ваша папка 1/' +'bestnets.npy', allow_pickle = True)[:2,:]\n",
        "# часть лучших сетей другого отбора\n",
        "#bn_2 = np.load('... ваша папка 2/' +'bestnets.npy', allow_pickle = True)[:2,:]\n",
        "# соединяем в один список для посева\n",
        "#load_nets = np.vstack([bn_1, bn_2])\n",
        "posev = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eGe0cF-BB3g"
      },
      "source": [
        "Если создали выше массив load_nets, то нише вместо\n",
        "posev = []\n",
        "нужно сделать\n",
        "posev = load_nets\n",
        "Если просто хотите передать один список вами сохраненный, то укажите путь до папки в крневой папке вами выше указанной при загрузке билиотеки os\n",
        "your_directory = /....../\n",
        "posev = np.load(your_directory + 'bestnets.npy', allow_pickle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLeBpRT1BB3g",
        "outputId": "7a70a85d-7bef-4a65-86e4-97da1e436abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2858/3052 [===========================>..] - ETA: 2s - loss: 0.0915Укажите количество сетей для посева: 0\n",
            "3019/3052 [============================>.] - ETA: 0s - loss: 0.0915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Пробегаемся по всем эпохам:   0%|          | 0/10 [00:00<?, ?epohs/s]\n",
            "Проходимся по популяциям:   0%|          | 0/7 [00:00<?, ?popul/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3049/3052 [============================>.] - ETA: 0s - loss: 0.0915\n",
            "MIX - создалась\n",
            "Epoch 1/5\n",
            "3052/3052 [==============================] - 45s 15ms/step - loss: 0.0915 - val_loss: 0.0911\n",
            "Epoch 5/5\n",
            "3052/3052 [==============================] - 66s 22ms/step - loss: 0.0914 - val_loss: 0.0912\n",
            "3052/3052 [==============================] - 78s 21ms/step - loss: 0.0929 - val_loss: 0.0911\n",
            "Epoch 2/5\n",
            "477/477 [==============================] - 5s 6ms/step\n",
            "3052/3052 [==============================] - 41s 13ms/step - loss: 0.0920 - val_loss: 0.0913\n",
            "Epoch 3/5\n",
            "3052/3052 [==============================] - 31s 10ms/step - loss: 0.0919 - val_loss: 0.0913\n",
            "Epoch 4/5\n",
            " 966/3052 [========>.....................] - ETA: 19s - loss: 0.0921"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# ВЕРСИЯ КОДА С ПОСЕВОМ и генетикой в создании новых популяций\n",
        "\n",
        "# Сохраняем массивы лучших моделей на диск\n",
        "# [[[bot_pop_1],[blockov_list_1],[bot_1]],[[bot_pop_1],[blockov_list_1],[bot_1]]]\n",
        "# куда  пишет данные этот код\n",
        "directory = 'model/'\n",
        "\n",
        "########### посев сетей вначале кода ############################################\n",
        "posev = [] # смотри пояснения выше как передать сюда ранее созданные данные\n",
        "# если еще нет список моделий, то ввести 0\n",
        "# или можно вручную списки подать, указав вместо 0, сколько будкт сетей\n",
        "# последовательно в ответ ввести  листы [bot_pop], [blockov_list], [bot]\n",
        "\n",
        "# в текстовой ячейке ниже есть 2 сети для посева вручную\n",
        "\n",
        "########### для подсевания лучших сетей прошлых эпох ###########################\n",
        "waitnets = 3 # сколько выводим лучших для для изучения и посева\n",
        "dw = 0.4 # доля лучших с прошлых эпох для подсева\n",
        "frbest = 3 # как часто подсевыем лучших с прошлых эпох\n",
        "################################################################################\n",
        "\n",
        "########### папаметпы для генерируемых сетей ###################################\n",
        "activ_lays =['relu', 'elu', 'tanh', 'sigmoid', 'selu', 'softmax',\n",
        "             'softplus', 'softsign', 'hard_sigmoid', 'exponential']\n",
        "# нужное количество входных нейроной\n",
        "neiro_out = y_train.shape[1]\n",
        "\n",
        "# функции активации для выходного слоя\n",
        "activ_out = ['linear']\n",
        "# словарь типов сетей\n",
        "style_net = {0: 'Dense',\n",
        "             1: 'Conv',\n",
        "             2: 'Recur',\n",
        "             None: 'MIX'\n",
        "}\n",
        "\n",
        "################################################################################\n",
        "q_tyblocks = 8    # макс количество генерируемых блоков для сети\n",
        "q_lays = 10       # макс количество слоев в блоках\n",
        "################################################################################\n",
        "verbouse = 'auto' # 0 - silent выводить или нет точность по ходу обучения\n",
        "epohs = 10        # Количество эпох для поиска\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "n = 10            # количество ботов популяции\n",
        "p = 7             # количество популяций\n",
        "\n",
        "dn = 0.3 # доля выживших ботов\n",
        "dp = 0.3 # доля выживших популяций\n",
        "\n",
        "dneff = 0.1 # доля выживших ботовию по эффективности\n",
        "dpeff = 0.1 # доля выживших популяций\n",
        "            # по эффективности\n",
        "\n",
        "prb_randbot = 0.2 # вероятность появления случайного бота в новой популяции\n",
        "mutp = 0.4   # Коэфициент мутаций при создании мегабота новой популяции\n",
        "mutn = 0.45  # Коэфициент мутаций при создании бота новой сети в популяции\n",
        "\n",
        "dpsurv = 0.8 # доля от выживших ботов популяции используемыех в родителях\n",
        "dnsurv = 0.8 # доля от выживших ботов мегапопуляции используемыех в родителях\n",
        "################################################################################\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "nsurv = max(2,round(dn* n))  # Кол-во выживших ботов мин 2 для родителей\n",
        "psurv = max(2,round(dp * p)) # Кол-во выживших популяций\n",
        "\n",
        "nsurv_eff = max(1,round(dneff * n)) # Коли-во выживших ботов поп-ии по эффект.\n",
        "psurv_eff = max(1,round(dpeff * p)) # Кол-во выживших ботов мегапоп по эффект.\n",
        "\n",
        "nnew = max(0, n - nsurv - nsurv_eff)  # Кол-во новых ботов\n",
        "pnew = max(0, p - psurv - psurv_eff)  # Кол-во новых популяций\n",
        "\n",
        "parents_n = round(nsurv*dnsurv) # выж. боты популяции используемые в родителях\n",
        "parents_p = round(psurv*dpsurv) # выж. боты мегапопуляции используемые в родит.\n",
        "\n",
        "sevbest = round(waitnets*dw) # сколько подсеем лучших с прошлых эпох\n",
        "################################################################################\n",
        "\n",
        "\n",
        "################################################################################\n",
        "popul = []         # обнулении популяции\n",
        "val_p = []         # обнулении точности популяции\n",
        "# создаем мегопопуляцию популяций ботов\n",
        "mega_popul = []\n",
        "mega_info = []\n",
        "botpop_lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# для посева из определенных моделей нужно создвть лист сетей попримеру\n",
        "# или ввести 0 при запросе input()\n",
        "if posev == []: posev = posev_net()\n",
        "\n",
        "for m in range(p):\n",
        "############# ПОСЕВ ############################################################\n",
        "    # сеем популяции из листа posev\n",
        "    if posev != [] and m < len(posev):\n",
        "        bot_pop = posev[m][0]\n",
        "        blockov_list = posev[m][1]\n",
        "        popul = []                 # Создаем пустую популяцию\n",
        "        popul.append(posev[m][2])  # задаем первого бота популяции из сева\n",
        "        for i in range(1,n):       # Проходим по всей длине популяции от 1\n",
        "            # создаем оставшихся случайнонных ботов из сеяного blockov_list\n",
        "            # определяем тип создания модели\n",
        "            choosing_net = Set_net(bot_pop[2], activ_lays, activ_out, neiro_out)\n",
        "            # инициализируем класс структуры блоков на основе парраметров сети\n",
        "            maker_blocks = Make_blocks(choosing_net)\n",
        "            bot = maker_blocks.buildblock_bot(blockov_list)\n",
        "            popul.append(bot)      # добавляем бота в популяцию\n",
        "\n",
        "################################################################################\n",
        "    # генерируем бота популяции\n",
        "    else: # если нет посева или если посев менее нужного количества\n",
        "        # случайно выбираем тип популяции\n",
        "        type_net = random.choice((None, 0, 1, 2))\n",
        "        # инициализируем Set_net на основе заданных парамметров\n",
        "        choosing_net = Set_net(type_net, activ_lays, activ_out, neiro_out)\n",
        "        # инициализируем класс структуры блоков на основе парраметров сети\n",
        "        maker_blocks = Make_blocks(choosing_net)\n",
        "        bot_pop = maker_blocks.buildpopulbot(q_tyblocks, q_lays)\n",
        "\n",
        "        # генерируем из состав блоков из к-ва блоков и слоев\n",
        "        structure = [np.random.randint(0,bot_pop[1]) for i in range(bot_pop[0])]\n",
        "        # создаем единый список блоков для популяции\n",
        "        blockov_list = maker_blocks.sostav_blockov(structure)\n",
        "        popul = []             # Создаем пустую популяцию\n",
        "        for i in range(n):     # Проходим по всей длине популяции\n",
        "            # создаем очередного случайнонного бота на основе blockov_list\n",
        "            bot = maker_blocks.buildblock_bot(blockov_list)\n",
        "            popul.append(bot)  # добавляем бота в популяцию\n",
        "\n",
        "    mega_popul.append(popul) # доб. популяцию в мегапопуляцию\n",
        "    mega_info.append(blockov_list) # доб. информацию о блоках  в мегапопуляцию\n",
        "    botpop_lst.append(bot_pop) # доб. мегабота популяции в лист ботов популяций\n",
        "if posev != []: print(f'Посеено {len(posev)} сетей')\n",
        "\n",
        "# счетчики\n",
        "avl_mdl = 0 # счетчик созданных моделей\n",
        "non_mdl = 0 # счетчик не созданных моделей\n",
        "ntk_mdl = 0 # счетчик моделей не подходящих под задачу\n",
        "gd_mdl  = 0 # счетчик моделей пригодных под задачу\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "# для сбора данных об эффективности обучения от эпохи\n",
        "ephtime_lst = []\n",
        "avlmdl_lst  = []\n",
        "gdmdl_lst   = []\n",
        "sval_lst    = []\n",
        "seff_lst    = []\n",
        "svalp_lst   = []\n",
        "seffp_lst   = []\n",
        "bestnets = []\n",
        "val_best = []\n",
        "################################################################################\n",
        "\n",
        "# Пробегаемся по всем эпохам\n",
        "for it in tqdm(range(epohs), unit =\"epohs\",  # Пробегаемся по всем эпохам\n",
        "                   desc =\"Пробегаемся по всем эпохам\"):\n",
        "    val_p = []\n",
        "    eff_p = []\n",
        "    curr_time = time.time()\n",
        "    for m in tqdm(range(p), unit =\"popul\",\n",
        "                desc =\"Проходимся по популяциям\"): # проходимся по популяциям\n",
        "        popul = mega_popul[m]       # берем очередную популяцию\n",
        "        blockov_list = mega_info[m] # берем информацию и популяции\n",
        "        bot_pop = botpop_lst[m]     # берем очередного мегабота популяцию\n",
        "        val = []\n",
        "        eff = [] #  список для списков по среднему обучению модели в fit()\n",
        "        for i in range(n): # Проходим по всей длине популяции\n",
        "            bot = popul[i] # Берем очередного бота\n",
        "\n",
        "            ########################################\n",
        "            # определяем тип создания модели\n",
        "            choosing_net = Set_net(bot_pop[2], activ_lays, activ_out, neiro_out)\n",
        "            # инициализируем класс структуры блоков на основе парраметров сети\n",
        "            maker_blocks = Make_blocks(choosing_net)\n",
        "            # инициализируем класс формирования сети\n",
        "            regress_model = WildregressModel(INSHAPE)\n",
        "            # тип сети для отображения\n",
        "            discription = style_net[bot_pop[2]]\n",
        "            ###########################################\n",
        "\n",
        "           #####################################################################\n",
        "           #               ОЦЕНКА МОДЕЛИ ОТ БОТА ПОПУЛЯЦИИ                     #\n",
        "           #####################################################################\n",
        "            try:\n",
        "              # пробуем создать модель\n",
        "              gen_model = regress_model(bot_pop,      # бот_популяции сетей\n",
        "                                        bot,          # бот парам-в слоев сети\n",
        "                                        blockov_list, # список имен слоев сети\n",
        "                                        maker_blocks # класс построения блоков\n",
        "                                         )\n",
        "              # если превысили время, то gen_model - просто сообщение\n",
        "              if type(gen_model) == str:\n",
        "                  print(gen_model)\n",
        "                  testing = False\n",
        "              else: # значит модель создалась\n",
        "                  print('\\n\\r' + discription + ' - создалась')\n",
        "                  testing = True\n",
        "                  avl_mdl+=1\n",
        "\n",
        "              # Вычисляем точность текущего бота\n",
        "              try:\n",
        "                  if testing:\n",
        "                      # оптимизатор\n",
        "                      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "                      # функция потерь\n",
        "                      loss = tf.keras.losses.MSE\n",
        "                      # оценка по времени и смешанной точности нашей модели\n",
        "                      result = evaluate_model(\n",
        "                      # собственные парамметры функции\n",
        "                      model = gen_model,           # тестируемая модель\n",
        "                      y_scaler = Y_SCAILER,        # обученный скейлер для y\n",
        "                      train_gen = train_datagen,   # генератор данных для обучения\n",
        "                      val_gen = val_datagen,       # генератор данных для проверки\n",
        "                      ep = 5,                      # эпох обучения\n",
        "                      verb = verbouse,             # отображать ли обучение\n",
        "                      optimizer = optimizer,       # оптимизатор\n",
        "                      loss = loss,                 # функция потерь\n",
        "                      channels = np.arange(PREDICT_LAG),# Отображение сводки модели\n",
        "                      predict_lag = PREDICT_LAG)   # На сколько шагов предсказание\n",
        "\n",
        "                      # выводим результат оценки\n",
        "                      # если превысили время, то gen_model - просто сообщение\n",
        "                      if type(result) == str:\n",
        "                        print('\\n\\r' + result)\n",
        "                        ntk_mdl+=1\n",
        "                        f = 500\n",
        "                        tlrn = 500\n",
        "                      else: # значит модель протестировалась\n",
        "                        f = result[0]\n",
        "                        tlrn = result[1]\n",
        "                        print('\\n\\r' + discription + ' - подошла под задачу')\n",
        "                        gd_mdl+=1\n",
        "\n",
        "                  else:\n",
        "                    print('\\n\\r' + discription + ' - слишком долго создавалась')\n",
        "                    ntk_mdl+=1\n",
        "                    f = 600\n",
        "                    tlrn = 600\n",
        "\n",
        "\n",
        "              except Exception:\n",
        "              # если не создалась то пишем плохую точность\n",
        "                  print('\\n\\r' + discription + ' - не подошла под задачу')\n",
        "                  ntk_mdl+=1\n",
        "                  f = 800\n",
        "                  lrn = 800\n",
        "\n",
        "            except Exception:\n",
        "                # если не создалась то пишем плохую точность\n",
        "              print('\\n\\r' + discription + ' - не создалась')\n",
        "              non_mdl+=1\n",
        "              f = 1000\n",
        "              tlrn = 1000\n",
        "\n",
        "            print(f'\\n\\rОценка модели {f} и время {tlrn}')\n",
        "\n",
        "            val.append(f)       # Добавляем полученное значение в список val\n",
        "            eff.append(tlrn*f) # сохраняем время эффективность обучения модели\n",
        "           #####################################################################\n",
        "\n",
        "        ########################################################################\n",
        "        # Сортируем val\n",
        "        sval = sorted(val, reverse=0)\n",
        "        val_p.append(sval)\n",
        "        #для сбора динамики точности от популяции\n",
        "        sval_lst.append(np.log10(sval[0]))\n",
        "\n",
        "        # Сортируем по эффективности\n",
        "        seff = sorted(eff, reverse=0)\n",
        "        eff_p.append(seff)\n",
        "        # для сбора динамики эффективности от популяции\n",
        "        seff_lst.append(np.log10(seff[0]))\n",
        "        ########################################################################\n",
        "\n",
        "        clear_output()\n",
        "        ########################################################################\n",
        "        # сбор|вывод данных эффективности поиска от популяции к популяции\n",
        "        try:\n",
        "            avlmdl = round(avl_mdl/(avl_mdl+non_mdl),2)\n",
        "            avlmdl_lst.append(avlmdl)\n",
        "            nonmdl = round(non_mdl/(avl_mdl+non_mdl),2)\n",
        "            gdmdl = round(gd_mdl/(avl_mdl),2)\n",
        "            gdmdl_lst.append(gdmdl)\n",
        "            ntkmdl = round(ntk_mdl/(avl_mdl),2)\n",
        "            # Показываем ход генитеческого поиска\n",
        "            show_pocess_1(avlmdl_lst, gdmdl_lst, sval_lst, seff_lst)\n",
        "            print(f'\\n\\rМегапопуляция {m}, эпоха {it+1}')\n",
        "            print(f'\\n\\rМодели популяции: создано {[avl_mdl,avlmdl]} брак {[non_mdl,nonmdl]}')\n",
        "            print(f'\\n\\rМодели популяции: пригодны {[gd_mdl,gdmdl]} не пригодны {[ntk_mdl,ntkmdl]}')\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    ############################################################################\n",
        "    # сбор и вывод данных для оценки эффективности поиска от эпохи\n",
        "    # сорт. список точностей мегапопуляции отсортированые точностями популяций\n",
        "    sval_p = sorted(val_p, key=lambda x: x[0])\n",
        "    # сортируем список точностей мегапопуляции по эффективности\n",
        "    seff_p = sorted(eff_p, key=lambda x: x[0])\n",
        "    eph_time = time.time() - curr_time\n",
        "    # собираем для контроля поиска и отображения\n",
        "    svalp_lst.append(np.log10(sval_p[0][0]))\n",
        "    seffp_lst.append(np.log10(seff_p[0][0]))\n",
        "    ephtime_lst.append(eph_time)\n",
        "\n",
        "    ############################################################################\n",
        "    # Показываем ход генитеческого поиска\n",
        "    if it > 1: show_process_2(svalp_lst, seffp_lst, ephtime_lst)\n",
        "\n",
        "    # Показыааем результаты лучших ботов\n",
        "    acc_models = np.array(sval_p)[:4,:4]\n",
        "    eff_models = np.array(seff_p)[:4,:4]\n",
        "    to_end = round(np.mean(ephtime_lst)*(epohs-it-1))\n",
        "    print(f'\\n\\rЭпоха {it}, точность моделей {acc_models}')\n",
        "    print(f'\\n\\rВремя на эпоху {eph_time}, эффективность моделей {eff_models}')\n",
        "    print(f'\\n\\rДо окончания поиска {to_end} сек.')\n",
        "    ############################################################################\n",
        "\n",
        "    ########## пересохраняем каждую эпоху данные ###############################\n",
        "    saver([mega_popul, botpop_lst, mega_info, svalp_lst, ephtime_lst], directory)\n",
        "    # это можно взять в свернутый лист автопосев на случай сбоя колаба\n",
        "    # то возобновить код с момента создания новых мега популяций и популяций\n",
        "    ############################################################################\n",
        "\n",
        "    ############################################################################\n",
        "    #   ФОРМИРОВАНИЕ НОВЫХ ПОПУЛЯЦИЙ НА ОСНОВЕ ПОЛУЧЕННЫХ ОЦЕНОК               #\n",
        "    ############################################################################\n",
        "    newmega_popul = []\n",
        "    newmega_info  = []\n",
        "    newbotpop_lst = []\n",
        "    newtime_mega  = []\n",
        "    # записываем данные лучших по точночти сетей\n",
        "    for m in range(psurv): # проходимся по выжившим мега-популяциям\n",
        "        idx_p = val_p.index(sval_p[m])  # индекс из списка лучших\n",
        "        newmega_popul.append(mega_popul[idx_p])\n",
        "        newmega_info.append(mega_info[idx_p])\n",
        "        newbotpop_lst.append(botpop_lst[idx_p])\n",
        "\n",
        "    # записываем эффективных  ботов популяций\n",
        "    for m in range(psurv_eff): #\n",
        "        idx_p = eff_p.index(seff_p[m])  # индекс из списка эффективных\n",
        "        newmega_popul.append(mega_popul[idx_p])\n",
        "        newmega_info.append(mega_info[idx_p])\n",
        "        newbotpop_lst.append(botpop_lst[idx_p])\n",
        "\n",
        "    # идем по отобранным популяциям точных и эффективных\n",
        "    for m in range(psurv+psurv_eff):\n",
        "        newpopul = []\n",
        "        newtime_pop= []\n",
        "        popul = newmega_popul[m]\n",
        "        blockov_list = newmega_info[m]\n",
        "        bot_pop = newbotpop_lst[m]\n",
        "\n",
        "        # записываем отобранных ботов в популяции\n",
        "        for i in range(nsurv):\n",
        "            idx = val.index(sval[i])  # индекс бота лучших в списке val\n",
        "            newpopul.append(popul[idx])\n",
        "        # записываем эффективных ботов в популяци\n",
        "        for i in range(nsurv_eff):\n",
        "            idx = eff.index(seff[i]) # индекс бота эффекивных в списке val\n",
        "            newpopul.append(popul[idx])\n",
        "\n",
        "        # берем ген определяющий тип сети популяции\n",
        "        type_net = bot_pop[2]\n",
        "        choosing_net = Set_net(type_net, activ_lays, activ_out, neiro_out)\n",
        "        ## инициализируем класс структуры блоков на основе параметров сети\n",
        "        maker_blocks = Make_blocks(choosing_net)\n",
        "        bots_random = [maker_blocks.buildblock_bot(blockov_list) \\\n",
        "                       for i in range(nnew)]\n",
        "        # Проходимся в цикле nnew-раз\n",
        "        for i in range(nnew):\n",
        "            idxp =  np.random.randint(0, nsurv + nsurv_eff, parents_n)\n",
        "            bots_parent = [newpopul[i] for i in idxp]\n",
        "\n",
        "            newbot = []  # Создаем пустой список под значения нового бота\n",
        "            # Пробегаем по всей длине бота\n",
        "            for j in range(len(blockov_list)):\n",
        "              k = np.random.randint(0, parents_n)\n",
        "              x = bots_parent[k][j]\n",
        "\n",
        "              # С вероятностью mutn устанавливаем значение бота\n",
        "              if (np.random.random() < mutn):\n",
        "                k = np.random.randint(0, nnew)\n",
        "                x = bots_random[k][j]\n",
        "\n",
        "              newbot.append(x)      # Доб. очередное значение в нового бота\n",
        "            newpopul.append(newbot) # Доб. бота в новую популяцию\n",
        "        # Собираем популяцию\n",
        "        popul = newpopul\n",
        "        newmega_popul.append(popul)\n",
        "        newmega_info.append(blockov_list)\n",
        "        newbotpop_lst.append(bot_pop)\n",
        "\n",
        "        ########## пересохраняем каждую эпоху данные ###########################\n",
        "        saver([newmega_popul, newbotpop_lst, newmega_info], directory)\n",
        "        # это можно взять в свернутый лист автопосев на случай сбоя колаба\n",
        "        # то возобновить код с момента создания новых мега популяций и популяций\n",
        "        ########################################################################\n",
        "\n",
        "    ##################### ПОДСКАЗКА ДЛЯ УЛУЧШЕНИЯ ##############################\n",
        "    # Можно тут организовать тригер, чтобы имея сохраненными newmega_popul,\n",
        "    # newbotpop_lst, newmega_info на диске, запускать цихл не вначале, а с этого\n",
        "    # момента, загрузив вначале их в код.\n",
        "    ############################################################################\n",
        "\n",
        "    ########### Сортировка и сохранение лушх сетей #############################\n",
        "    # получаем индексы  лучших сетей по всем мегапопуляциям\n",
        "    idxs, sval_best = get_idxbest(sval_p, waitnets)\n",
        "    # получаем спиок лучших сетей по всем мегапопуляциям на эпохе\n",
        "    newbestnets = get_bestnets(idxs, newbotpop_lst, newmega_info, newmega_popul)\n",
        "    for i in range(waitnets):\n",
        "        bestnets.append(newbestnets[i])\n",
        "    # объединяем списки\n",
        "    val_best = np.hstack((val_best,sval_best))\n",
        "    idx = np.argsort(val_best)[:waitnets] # получаем индексы для сортировки\n",
        "    val_best = val_best[idx]\n",
        "    bestnets = [bestnets[i] for i in idx]\n",
        "    np.save(directory + 'bestnets.npy', bestnets)\n",
        "    ############################################################################\n",
        "\n",
        "    ############# ПОДСЕВ лучшх сетей с прошлых эпох ############################\n",
        "    if (it > 1 and  it % frbest == 0) and (p - psurv - psurv_eff - sevbest) > 0:\n",
        "        pbest = sevbest\n",
        "        posev_lst = bestnets[:pbest]\n",
        "        # сеем популяции из листа posev\n",
        "        for m in range(pbest):\n",
        "            bot_pop = posev_lst[m][0]\n",
        "            blockov_list = posev_lst[m][1]\n",
        "            popul = []                 # Создаем пустую популяцию\n",
        "            # задаем первого бота популяции из сева\n",
        "            popul.append(posev_lst[m][2])\n",
        "            # Проходим по всей длине популяции от 1\n",
        "            for i in range(1,n):\n",
        "                # берем ген определяющий тип сети популяции\n",
        "                type_net = bot_pop[2]\n",
        "                choosing_net = Set_net(type_net, activ_lays, activ_out,\n",
        "                                       neiro_out)\n",
        "                # иници/ класс структуры блоков на основе парраметров сети\n",
        "                maker_blocks = Make_blocks(choosing_net)\n",
        "                # создаем оставшихся случайнонных ботов из сеяного blockov_list\n",
        "                bot = maker_blocks.buildblock_bot(blockov_list)\n",
        "                popul.append(bot)      # добавляем бота в популяцию\n",
        "            # добавляем популяцию в мегапопуляцию\n",
        "            newmega_popul.append(popul)\n",
        "            # добавляем информацию о блоках  в мегапопуляцию\n",
        "            newmega_info.append(blockov_list)\n",
        "            # добавляем мегабота популяции в лист ботов популяций\n",
        "            newbotpop_lst.append(bot_pop)\n",
        "        print(f'\\n\\rПосеено {len(posev_lst)} сетей из лучших прошлых эпох')\n",
        "    else:\n",
        "        pbest = 0\n",
        "\n",
        "    ############################################################################\n",
        "    #     создаем новых ботов новых популяций основе скрещиваний и мутаций     #\n",
        "    ############################################################################\n",
        "    pneweph = pnew - pbest # сколько  создаем новых популяций от родителей\n",
        "    # случайно выбираем тип сети\n",
        "    type_net = random.choice((None, 0, 1, 2))\n",
        "    # создаем новых ботов в эту популяцию\n",
        "    choosing_net = Set_net(type_net, activ_lays, activ_out, neiro_out)\n",
        "    # инициализируем класс структуры блоков на основе парраметров сети\n",
        "    maker_blocks = Make_blocks(choosing_net)\n",
        "    bots_poprandom = [maker_blocks.buildpopulbot(q_tyblocks, q_lays) \\\n",
        "                      for i in range(pnew - pbest)]\n",
        "    # создаем популяции от родителей\n",
        "    for m in range(pneweph):\n",
        "        idxp =  np.random.randint(0, psurv + psurv_eff, parents_p)\n",
        "        bots_popparent = [newbotpop_lst[i] for i in idxp]\n",
        "        # Создаем пустой список под значения нового мегабота\n",
        "        newbot_pop = []\n",
        "        # Получаем случайное число в диапазоне от 0 до 1\n",
        "        if np.random.random() < prb_randbot:\n",
        "            k = np.random.randint(0, pneweph)\n",
        "            bot_pop = bots_poprandom[k]  # берем совсем случайный бот пупуляции\n",
        "\n",
        "        else:  # создаем бот пупуляции генетикой\n",
        "            # Пробегаем по всей длине бота\n",
        "            for j in range(len(bots_poprandom[0])):\n",
        "                  k = np.random.random_integers(0, parents_p-1)\n",
        "                  x = bots_popparent[k][j]\n",
        "\n",
        "                  # С вер. mutp ставим значение бота из случайного мегабота\n",
        "                  if np.random.random() < mutp:\n",
        "                      k = np.random.randint(0, pneweph)\n",
        "                      x = bots_poprandom[k][j]\n",
        "                  newbot_pop.append(x)  # Доб. ген в нового мегабота\n",
        "            bot_pop = newbot_pop        # бот популяции создан\n",
        "\n",
        "        # генерируем из состав блоков популяции\n",
        "        structure  = [np.random.randint(0, bot_pop[1]) for i in \\\n",
        "                      range(bot_pop[0])]\n",
        "        # случайно выбираем тип сети\n",
        "        type_net = random.choice((None, 0, 1, 2))\n",
        "        choosing_net = Set_net(type_net, activ_lays, activ_out, neiro_out)\n",
        "        # инициализируем класс структуры блоков на основе парраметров сети\n",
        "        maker_blocks = Make_blocks(choosing_net)\n",
        "        # создаем единый список блоков для популяции\n",
        "        blockov_list = maker_blocks.sostav_blockov(structure)\n",
        "\n",
        "        popul = [] # Создаем пустую популяцию\n",
        "        # Проходим по всей длине популяции\n",
        "        for i in range(n):\n",
        "            # создаем очередного случайнонного бота на основе blockov_list\n",
        "            bot = maker_blocks.buildblock_bot(blockov_list)\n",
        "            popul.append(bot)  # доб. бота в популяцию\n",
        "        newmega_popul.append(popul) # доб. популяцию в мегапопуляцию\n",
        "        newmega_info.append(blockov_list) # доб. информацию о блоках\n",
        "        newbotpop_lst.append(bot_pop) # доб. мегабота\n",
        "\n",
        "    # перезаписываем информацию\n",
        "    mega_popul = newmega_popul\n",
        "    mega_info = newmega_info\n",
        "    botpop_lst = newbotpop_lst\n",
        "    ############################\n",
        "\n",
        "    ########## пересохраняем каждую эпоху данные ###############################\n",
        "    saver([mega_popul, botpop_lst, mega_info, svalp_lst], directory)\n",
        "    # это можно взять в свернутый лист автопосев на случай сбоя колаба\n",
        "    # то возобновить код с момента создания новых мега популяций и популяций\n",
        "    ############################################################################\n",
        "\n",
        "finish_time = time.time() - start_time\n",
        "print(f'\\n\\rОбщее время подбора за {epohs} эпох по {p*n} моделей составило {finish_time}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnhYrtP7BB3i"
      },
      "source": [
        "# ПРИМЕР ДЛЯ ПОСЕВА ВРУЧНУЮ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDti7-ZYBB3i"
      },
      "outputs": [],
      "source": [
        "# вариант из презентации\n",
        "bot_pop = [7, 1, None, 1, 16, 7, 0, 0, 0, 0]\n",
        "setblockov = [[], [], ['Conv1DT'], ['Dense'], [], [], []]\n",
        "bot = [[], [], [64, 4], [128], [], [], []]\n",
        "\n",
        "# иной вариант\n",
        "bot_pop = [4, 1, None, 1, 128, 6, 0, 0, 0, 0]\n",
        "setblockov = [[], ['Lstm'], ['Conv1D_dilation_block'], []]\n",
        "bot = [[], [4], [8, 2], []]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_muUbmWBB3i"
      },
      "source": [
        "# После генетики"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPYWvE5XBB3i"
      },
      "source": [
        "# Генерация нейронки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knreO4Q3BB3i"
      },
      "outputs": [],
      "source": [
        "directory = '..папка куда сохранял ваш код выше../'  # куда пишет данные код\n",
        "########### папаметпы для генерируемых сетей ###################################\n",
        "activ_lays =['relu', 'elu', 'tanh', 'sigmoid', 'selu', 'softmax',\n",
        "             'softplus', 'softsign', 'hard_sigmoid', 'exponential']\n",
        "# нужное количество входных нейроной\n",
        "neiro_out = y_train.shape[1]\n",
        "\n",
        "# функции активации для выходного слоя\n",
        "activ_out = ['linear']\n",
        "\n",
        "# загружаем список парамметров лучших сетей\n",
        "save_nets = np.load(directory+'bestnets.npy', allow_pickle = True)\n",
        "\n",
        "# генерируем список моделей в количестве n\n",
        "set_models = getnetfrombest(save_nets, activ_lays,\n",
        "                            activ_out, neiro_out,\n",
        "                            limit = TIMELIMIT_1,\n",
        "                            n = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdXWwd80BB3i"
      },
      "outputs": [],
      "source": [
        "k = 0 # указываем индекс от 0 до n-1 для выбора модели\n",
        "good_model = set_models[k]\n",
        "good_model.call = tf.function(good_model.call)\n",
        "\n",
        "# Отображение сводки модели\n",
        "good_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iDTOi-cBB3i"
      },
      "outputs": [],
      "source": [
        "# дерево модели\n",
        "tf.keras.utils.plot_model(good_model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEcU14BUBB3i"
      },
      "source": [
        "# Обучение сгенерированной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnlR2ow3BB3j"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "# Custom Callback To Include in Callbacks List At Training Time\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "\n",
        "# очистка ОЗУ\n",
        "clear_ozu = GarbageCollectorCallback()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8X2aKgtBB3p"
      },
      "source": [
        "# Вариант 1 - Базавое как в лекции"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJtPB0xMBB3p"
      },
      "outputs": [],
      "source": [
        "# оптимизатор\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-3)\n",
        "\n",
        "# функция потерь\n",
        "loss = tf.keras.losses.Huber() # MSE #\n",
        "good_model.compile(optimizer = optimizer, loss = loss)\n",
        "\n",
        "# понижение шага\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                 mode='min',\n",
        "                                                 factor = 0.8,\n",
        "                                                 patience = 3,\n",
        "                                                 min_lr = 1e-9,\n",
        "                                                 verbose = 1)\n",
        "\n",
        "# остановка\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    patience=17,\n",
        "    mode='min',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbtbT_m1BB3p"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "# обучение модели вашей\n",
        "history = good_model.fit(train_datagen,                  # генератор данных для обучения\n",
        "                          validation_data = val_datagen, # генератор данных для проверки\n",
        "                          epochs = 150,\n",
        "                          callbacks=[early_stopping, reduce_lr, clear_ozu],\n",
        "                          verbose = 1)\n",
        "\n",
        "end = time()\n",
        "print(f'Время обучения {end:.5f} сек.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQN1sZzuBB3p"
      },
      "source": [
        "# Вариант 2 - используя CyclicalLearningRate и SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHdehEtqBB3p"
      },
      "outputs": [],
      "source": [
        "# дополнительная библиотека tensorflow_addons\n",
        "#!pip install -q -U tensorflow_addons\n",
        "\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz5BMAlQBB3q"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 1e-3\n",
        "MAX_LR = 1e-2\n",
        "\n",
        "steps_per_epoch = len(x_train) // BATCH_SIZE\n",
        "\n",
        "# понижение шага циклами\n",
        "clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
        "    maximal_learning_rate=MAX_LR,\n",
        "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
        "    step_size=2 * steps_per_epoch\n",
        ")\n",
        "# оптимизатор\n",
        "optimizer = tf.keras.optimizers.SGD(clr)\n",
        "\n",
        "# функция потерь\n",
        "loss = tf.keras.losses.Huber() #MSE #\n",
        "good_model.compile(optimizer = optimizer, loss = loss)\n",
        "\n",
        "# остановка\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    patience= 55,\n",
        "    mode='min',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb95iGxBBB3q"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "history = good_model.fit(train_datagen,                  # генератор данных для обучения\n",
        "                          validation_data = val_datagen, # генератор данных для проверки\n",
        "                          epochs = 150,\n",
        "                          callbacks=[early_stopping, clear_ozu],\n",
        "                          verbose = 1)\n",
        "\n",
        "end = time()\n",
        "print(f'Время обучения {end:.5f} сек.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE03UNSgBB3q"
      },
      "source": [
        "# Вариант 3 - используя взвешанное MSE\n",
        "пример https://towardsdatascience.com/how-to-create-a-custom-loss-function-keras-3a89156ec69b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLBlnB38BB3q"
      },
      "outputs": [],
      "source": [
        "len_period = PREDICT_LAG\n",
        "\n",
        "weights = []\n",
        "for i in range(len_period):\n",
        "  w = (len_period-i)/len_period\n",
        "  weights.append(w)\n",
        "\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sxJ6VeiBB3q"
      },
      "outputs": [],
      "source": [
        "def weight_mse(w):\n",
        "\n",
        "    def custom_mse(y_true, y_pred, w = w):\n",
        "        # разница target и predicted\n",
        "        loss = tf.keras.backend.square(y_pred - y_true)  # (batch_size, 2)\n",
        "\n",
        "        # умножаем на веса\n",
        "        loss*= w         # (batch_size, 2)\n",
        "\n",
        "        # усредняем ошибку\n",
        "        loss = tf.keras.backend.mean(loss, axis=-1)        # (batch_size,)\n",
        "        return loss\n",
        "    return custom_mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fIalLKkBB3q"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "INIT_LR = 1e-4\n",
        "MAX_LR = 1e-3\n",
        "\n",
        "steps_per_epoch = len(x_train) // BATCH_SIZE\n",
        "\n",
        "# понижение шага циклами\n",
        "clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
        "    maximal_learning_rate=MAX_LR,\n",
        "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
        "    step_size=2 * steps_per_epoch\n",
        ")\n",
        "# оптимизатор\n",
        "optimizer = tf.keras.optimizers.SGD(clr)\n",
        "# функция потерь\n",
        "loss = weight_mse(weights)\n",
        "good_model.compile(optimizer = optimizer, loss = loss)\n",
        "\n",
        "# понижение шага\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                 mode='min',\n",
        "                                                 factor = 0.8,\n",
        "                                                 patience = 3,\n",
        "                                                 min_lr = 1e-9, verbose = 1)\n",
        "# остановка\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    patience= 55,\n",
        "    mode='min',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zA1JfnVBB3q"
      },
      "outputs": [],
      "source": [
        "start = time()\n",
        "history = good_model.fit(train_datagen,                  # генератор данных для обучения\n",
        "                          validation_data = val_datagen, # генератор данных для проверки\n",
        "                          epochs = 200,\n",
        "                          callbacks=[early_stopping, clear_ozu],\n",
        "                          verbose = 1)\n",
        "\n",
        "end = time()\n",
        "print(f'Время обучения {end:.5f} сек.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDtGgTbVBB3q"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],\n",
        "         label='MSE ошибка на обучающем наборе')\n",
        "plt.plot(history.history['val_loss'],\n",
        "         label='MSE на проверочном наборе')\n",
        "plt.ylabel('MSE ошибка')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBZ-Unr9BB3q"
      },
      "source": [
        "# Оценка модели на VAL данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVgiEGD9BB3q"
      },
      "outputs": [],
      "source": [
        "# Прогнозируем данные текущей сетью\n",
        "(y_pred_val, y_true_val) = get_scalepred(good_model, XVAL, YVAL, Y_SCAILER) #Прогнозируем данные\n",
        "\n",
        "# Отображаем графики\n",
        "show_predict(0,                    # начало периода\n",
        "             y_true_val.shape[0],  # конец периода\n",
        "             [4],                  # по предсказанию на какие шаги отрисовываем\n",
        "             y_pred_val,           # предчказанные цены\n",
        "             y_true_val,           # реальные цены\n",
        "             PRED_PRICE,\n",
        "             figsize=(18,7))\n",
        "\n",
        "# Отображаем корреляцию\n",
        "# Проверяем корреляцию на глубину PREDICT_LAG шагов\n",
        "auto_corr([4],             # по предсказанию на какие шаги отрисовываем корреляцию\n",
        "          50,     # на сколько шагов предсказание\n",
        "          y_pred_val,      # предчказанные цены\n",
        "          y_true_val       # реальные цены\n",
        "          )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}